{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from workspace import nometools as nome\n",
    "from workspace import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_path = Path('..')\n",
    "steric_path = main_path / 'superposition' / 'clash_1KX5'\n",
    "intersect_path = main_path / 'Data' / 'intersect_regions'\n",
    "sliding_path = main_path / 'Data' / 'sliding_window_1kx5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize Steric Clash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = steric_path / 'x_y_dict'\n",
    "with open(infile, 'rb') as fin:\n",
    "    x_y_clash_dict = pickle.load(fin)\n",
    "\n",
    "x_y_clash_dict_norm_ = utils.normalize_clash_dict(x_y_clash_dict)\n",
    "\n",
    "meth_thres_range = [0, 10, 20]\n",
    "clash_thres_range = [5, 10, 20, 50]\n",
    "\n",
    "params = []\n",
    "for clash_thres in clash_thres_range:\n",
    "    for meth_thres in meth_thres_range:\n",
    "        k = \"c\" + str(clash_thres) + \"m\" + str(meth_thres)\n",
    "        params.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(x_y_clash_dict.values(), marker='o')\n",
    "plt.plot(x_y_clash_dict_norm_.values(), marker='o')\n",
    "plt.xticks(range(0,len(x_y_clash_dict.values())+5,5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_y_clash_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x_y_clash_dict.keys()), len(x_y_clash_dict_norm_.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sliding Window - This remains the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# region = 'promoter'\n",
    "# region = 'intron.1.start'\n",
    "# region = 'intron.1.end'\n",
    "# region = 'intron.2.start'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# infile = intersect_path / f'{region}.NDR.HCG.intersect.bed'\n",
    "# df_NDR = nome.get_nuc_pos_methylation(infile, region=region)\n",
    "\n",
    "# infile = intersect_path / f'{region}.NDR.HCG.random.intersect.bed'\n",
    "# df_NDR_random = nome.get_nuc_pos_methylation(infile, region=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_NDR.shape, df_NDR_random.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# infile = intersect_path / f'{region}.NOR.HCG.intersect.bed'\n",
    "# df_NOR = nome.get_nuc_pos_methylation(infile, region=region)\n",
    "\n",
    "# infile = intersect_path / f'{region}.NOR.HCG.random.intersect.bed'\n",
    "# df_NOR_random = nome.get_nuc_pos_methylation(infile, region=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_NOR.shape, df_NOR_random.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_NOR.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_NDR.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_NDR_sliding_windows = nome.make_sliding_windows_file(df_NDR, x_y_clash_dict, mask=True, region=region)\n",
    "# df_NDR_sliding_windows.to_csv(sliding_path / f'{region}.df_NDR_sliding_windows.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_NDR_sliding_windows_random = nome.make_sliding_windows_file(df_NDR_random, x_y_clash_dict, region=region)\n",
    "# df_NDR_sliding_windows_random.to_csv(sliding_path / f'{region}.df_NDR_sliding_windows_random.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_NDR_sliding_windows.shape, df_NDR_sliding_windows_random.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_NOR_sliding_windows = nome.make_sliding_windows_file(df_NOR, x_y_clash_dict, region=region)\n",
    "# df_NOR_sliding_windows.to_csv(sliding_path / f'{region}.df_NOR_sliding_windows.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_NOR_sliding_windows_random = nome.make_sliding_windows_file(df_NOR_random, x_y_clash_dict, region=region)\n",
    "# df_NOR_sliding_windows_random.to_csv(sliding_path / f'{region}.df_NOR_sliding_windows_random.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_NOR_sliding_windows.shape, df_NOR_sliding_windows_random.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_NDR_sliding_windows.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_NOR_sliding_windows.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Steric Clash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "def calc_perc_exp_clash_ident(x_y_clash_dict_norm, meth_in_window_tmp, meth_thres, clash_thres):    \n",
    "    count_ident = 0\n",
    "    cpg_positions = meth_in_window_tmp.keys()\n",
    "    for meth_pos in cpg_positions:\n",
    "        meth_rate = meth_in_window_tmp[meth_pos]\n",
    "        clash_perc = x_y_clash_dict_norm[meth_pos] \n",
    "        \n",
    "        if meth_rate > meth_thres:\n",
    "            if clash_perc <= clash_thres:\n",
    "                count_ident += 1\n",
    "        else:\n",
    "            if clash_perc > clash_thres:\n",
    "                count_ident += 1\n",
    "                \n",
    "    nbr_cpgs = len(cpg_positions)\n",
    "    perc_exp_clash_ident = float(count_ident)/float(nbr_cpgs)\n",
    "    \n",
    "    return perc_exp_clash_ident\n",
    "\n",
    "def calc_score_lists(df_sliding_windows, x_y_clash_dict_norm, params):\n",
    "    column_names = [\"refid_NOR\", \"trans_id\", \"refid\", \"NOR_nbr\", \"window_nbr\", \"nbr_CpGs\", \"nuc_rel_center\", \"nuc_region_length\"] + params\n",
    "    info_dict = dict()\n",
    "    for col in column_names:\n",
    "        info_dict[col] = []\n",
    "        \n",
    "    all_refids = list(df_sliding_windows[\"refid\"])\n",
    "    all_NOR_nbrs = list(df_sliding_windows[\"NOR_nbr\"])\n",
    "    refid_NORs = []\n",
    "    for ref, nor in zip(all_refids, all_NOR_nbrs):\n",
    "        refid_NORs.append(str(ref)+\"-\"+str(nor))\n",
    "    \n",
    "    info_dict[\"refid_NOR\"].extend(refid_NORs)\n",
    "    info_dict[\"trans_id\"].extend(list(df_sliding_windows[\"trans_id\"]))\n",
    "    info_dict[\"refid\"].extend(all_refids)\n",
    "    info_dict[\"NOR_nbr\"].extend(all_NOR_nbrs)\n",
    "    info_dict[\"window_nbr\"].extend(list(df_sliding_windows[\"window_nbr\"]))\n",
    "    info_dict[\"nbr_CpGs\"].extend(list(df_sliding_windows[\"nbr_meth_CpGs\"]))\n",
    "    info_dict[\"nuc_region_length\"].extend(list(df_sliding_windows[\"nuc_region_length\"]))\n",
    "    info_dict[\"nuc_rel_center\"].extend(list(df_sliding_windows[\"nuc_rel_center\"]))\n",
    "\n",
    "    all_scores =  list(df_sliding_windows[\"meth_rates_window\"]) #{34: 0.0, 35: 0.0,...}\n",
    "    c = 0\n",
    "    for row_df in tqdm(range(len(all_scores))):\n",
    "        c += 1\n",
    "        \n",
    "        # meth_rates_window = ast.literal_eval(all_scores[row_df])\n",
    "        meth_rates_window = all_scores[row_df]\n",
    "    \n",
    "        for param_str in params:\n",
    "            clash_thres = float(re.findall(r'\\d+', param_str)[0]) #c5m0\n",
    "            meth_thres = float(re.findall(r'\\d+', param_str)[1])\n",
    "            \n",
    "            perc_clash_ident = calc_perc_exp_clash_ident(x_y_clash_dict_norm, meth_rates_window, meth_thres, clash_thres)\n",
    "            info_dict[param_str].append(perc_clash_ident)\n",
    "            \n",
    "    #Built dataframe \n",
    "    df_scores = pd.DataFrame(0, index = np.arange(len(info_dict[column_names[0]])),columns = column_names)\n",
    "    for feat in column_names:\n",
    "        df_scores[feat] = info_dict[feat]\n",
    "\n",
    "    return df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# region = 'promoter'\n",
    "# region = 'intron.1.start'\n",
    "# region = 'intron.1.end'\n",
    "region = 'intron.2.start'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_path = main_path / 'Data' / 'sliding_window'\n",
    "df_NDR_sliding_windows = pd.read_csv(read_path / f'{region}.df_NDR_sliding_windows.csv')\n",
    "df_NDR_sliding_windows_random = pd.read_csv(read_path / f'{region}.df_NDR_sliding_windows_random.csv')\n",
    "df_NOR_sliding_windows = pd.read_csv(read_path / f'{region}.df_NOR_sliding_windows.csv')\n",
    "df_NOR_sliding_windows_random = pd.read_csv(read_path / f'{region}.df_NOR_sliding_windows_random.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NDR_sliding_windows['meth_rates_window'] = df_NDR_sliding_windows['meth_rates_window'].apply(ast.literal_eval)\n",
    "df_NDR_sliding_windows_random['meth_rates_window'] = df_NDR_sliding_windows_random['meth_rates_window'].apply(ast.literal_eval)\n",
    "df_NOR_sliding_windows['meth_rates_window'] = df_NOR_sliding_windows['meth_rates_window'].apply(ast.literal_eval)\n",
    "df_NOR_sliding_windows_random['meth_rates_window'] = df_NOR_sliding_windows_random['meth_rates_window'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NDR_sliding_windows.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NOR_sliding_windows.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NDR_score_exp = calc_score_lists(df_NDR_sliding_windows, x_y_clash_dict, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NDR_score_random = calc_score_lists(df_NDR_sliding_windows_random, x_y_clash_dict, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NDR_score_exp.shape, df_NDR_score_random.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NOR_score_exp = calc_score_lists(df_NOR_sliding_windows, x_y_clash_dict, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NOR_score_random = calc_score_lists(df_NOR_sliding_windows_random, x_y_clash_dict, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NOR_score_exp.shape, df_NOR_score_random.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NDR_score_exp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NDR_score_exp.to_csv(sliding_path / f'{region}.df_NDR_score_exp.csv', index=False)\n",
    "df_NDR_score_random.to_csv(sliding_path / f'{region}.df_NDR_score_random.csv', index=False)\n",
    "df_NOR_score_exp.to_csv(sliding_path / f'{region}.df_NOR_score_exp.csv', index=False)\n",
    "df_NOR_score_random.to_csv(sliding_path / f'{region}.df_NOR_score_random.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cohen's D and P values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from scipy import stats\n",
    "\n",
    "def calculate_cohens_d(list_EXP,list_RAND):\n",
    "    mEXP = np.mean(list_EXP)\n",
    "    sdEXP = np.std(list_EXP)\n",
    "    \n",
    "    mRAND = np.mean(list_RAND)\n",
    "    sdRAND = np.std(list_RAND)\n",
    "    \n",
    "    denom = np.sqrt(float(sdEXP**2 + sdRAND**2)/2.0)\n",
    "    cohens_d = float(mEXP-mRAND)/float(denom + 1e-6)\n",
    "    \n",
    "    return cohens_d\n",
    "\n",
    "def make_df_p_vals_cohens_d(df_scores_EXP, df_scores_RAND, params):\n",
    "    column_names = [\"nbr_CpGs\", \"parameter\", \"N_EXP\", \"N_RAND\", \"mean_EXP\", \"median_EXP\", \"std_EXP\", \"mean_RAND\",\n",
    "                    \"median_RAND\", \"std_RAND\", \"cohens_d\", \"is_normal_EXP\", \"is_normal_RAND\", \"pval_ttest\",\n",
    "                    \"t_stat\", \"pval_ranksums\", \"pval_ks_2samp\"]\n",
    "    info_dict = dict()\n",
    "    for col in column_names:\n",
    "        info_dict[col] = []\n",
    "\n",
    "    nbr_CpGs_list = list(set(list(df_scores_EXP[\"nbr_CpGs\"])))\n",
    "\n",
    "    for nbr_CpGs in nbr_CpGs_list:\n",
    "        df_scores_EXP_tmp = df_scores_EXP.loc[df_scores_EXP[\"nbr_CpGs\"] == nbr_CpGs]\n",
    "        df_scores_RAND_tmp = df_scores_RAND.loc[df_scores_RAND[\"nbr_CpGs\"] == nbr_CpGs]\n",
    "                    \n",
    "        for p in range(len(params)):\n",
    "            par_name = params[p]\n",
    "            EXP_scores = list(df_scores_EXP_tmp[par_name])\n",
    "            RAND_scores = list(df_scores_RAND_tmp[par_name])\n",
    "            \n",
    "            info_dict[\"nbr_CpGs\"].append(nbr_CpGs)\n",
    "            info_dict[\"parameter\"].append(par_name)\n",
    "            \n",
    "            info_dict[\"N_EXP\"].append(len(EXP_scores))\n",
    "            info_dict[\"N_RAND\"].append(len(RAND_scores))\n",
    "            \n",
    "            info_dict[\"mean_EXP\"].append(np.mean(EXP_scores))\n",
    "            info_dict[\"median_EXP\"].append(np.median(EXP_scores))\n",
    "            info_dict[\"std_EXP\"].append(np.std(EXP_scores))\n",
    "            \n",
    "            info_dict[\"mean_RAND\"].append(np.mean(RAND_scores))\n",
    "            info_dict[\"median_RAND\"].append(np.median(RAND_scores))\n",
    "            info_dict[\"std_RAND\"].append(np.std(RAND_scores))\n",
    "            \n",
    "            #EFFECT SIZE\n",
    "            cohens_d = calculate_cohens_d(EXP_scores, RAND_scores)\n",
    "            info_dict[\"cohens_d\"].append(cohens_d)\n",
    "            \n",
    "            #STAT TESTS\n",
    "            #is normal distributed? This function tests the null hypothesis that a sample comes from a normal distribution. If small -> ost likely not normal dustributed\n",
    "            pval_normal_EXP = stats.normaltest(EXP_scores)[1] if len(EXP_scores) >= 8 else -1\n",
    "            pval_normal_RAND = stats.normaltest(RAND_scores)[1] if len(EXP_scores) >= 8 else -1\n",
    "            \n",
    "            #students t\n",
    "            ttest_res = stats.ttest_ind(EXP_scores,RAND_scores,equal_var = False)\n",
    "            t_stat = ttest_res[0]\n",
    "            p_val_ttest = float(ttest_res[1])/2.0\n",
    "            \n",
    "            #ranksums, kstest\n",
    "            ranksums = scipy.stats.ranksums(EXP_scores,RAND_scores)[1]\n",
    "            ks_2samp = scipy.stats.ks_2samp(EXP_scores,RAND_scores)[1]\n",
    "    \n",
    "            info_dict[\"is_normal_EXP\"].append(pval_normal_EXP)\n",
    "            info_dict[\"is_normal_RAND\"].append(pval_normal_RAND)\n",
    "            info_dict[\"pval_ttest\"].append(p_val_ttest)\n",
    "            info_dict[\"t_stat\"].append(t_stat)\n",
    "            info_dict[\"pval_ranksums\"].append(ranksums)\n",
    "            info_dict[\"pval_ks_2samp\"].append(ks_2samp)\n",
    "            \n",
    "    #Built dataframe\n",
    "    df = pd.DataFrame(0, index = np.arange(len(info_dict[\"nbr_CpGs\"])),columns = column_names)\n",
    "    for feat in column_names:\n",
    "        df[feat] = info_dict[feat]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# region = 'promoter'\n",
    "# region = 'intron.1.start'\n",
    "# region = 'intron.1.end'\n",
    "region = 'intron.2.start'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NDR_score_exp = pd.read_csv(sliding_path / f'{region}.df_NDR_score_exp.csv')\n",
    "df_NDR_score_random = pd.read_csv(sliding_path / f'{region}.df_NDR_score_random.csv')\n",
    "df_NOR_score_exp = pd.read_csv(sliding_path / f'{region}.df_NOR_score_exp.csv')\n",
    "df_NOR_score_random = pd.read_csv(sliding_path / f'{region}.df_NOR_score_random.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NDR_pvalues = make_df_p_vals_cohens_d(df_NDR_score_exp, df_NDR_score_random, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NOR_pvalues = make_df_p_vals_cohens_d(df_NOR_score_exp, df_NOR_score_random, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NDR_pvalues.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "groups = df_NDR_pvalues.groupby(by='parameter')\n",
    "for par, df_tmp in groups:\n",
    "    plt.scatter(df_tmp['nbr_CpGs'], df_tmp['N_EXP'], label=par)\n",
    "\n",
    "# plt.axhline(y=50)\n",
    "plt.xlim(-2,30)\n",
    "# plt.ylim((10**1,10**6))\n",
    "# plt.legend()\n",
    "plt.xlabel('Number of CpGs in sliding window', fontsize=22)\n",
    "plt.ylabel('Sample size for Cohen’s D', fontsize=22)\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "groups = df_NOR_pvalues.groupby(by='parameter')\n",
    "for par, df_tmp in groups:\n",
    "    plt.scatter(df_tmp['nbr_CpGs'], df_tmp['N_EXP'], label=par)\n",
    "plt.xlim(-2,30)\n",
    "# plt.legend()\n",
    "plt.xlabel('Number of CpGs in sliding window', fontsize=22)\n",
    "plt.ylabel('Sample size for Cohen’s D', fontsize=22)\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_nbr_CpGs_cohensd(df_values, params):\n",
    "    plt.figure(figsize=(15,7))\n",
    "    ax = plt.subplot(1,1,1)\n",
    "    \n",
    "    nbr_CpGs_list = sorted(list(set(list(df_values[\"nbr_CpGs\"]))))\n",
    "\n",
    "    for par_name in params:\n",
    "        \n",
    "        df_values_tmp = df_values.loc[df_values[\"parameter\"] == par_name]\n",
    "        \n",
    "        x_nbr_cpg_vals = list(df_values_tmp[\"nbr_CpGs\"])\n",
    "        y_cohens_d_vals = list(df_values_tmp[\"cohens_d\"])\n",
    "        \n",
    "        if \"m0\" in par_name:\n",
    "            c = \"#117A65\"\n",
    "        if \"m10\" in par_name:\n",
    "            c = \"#45B39D\"\n",
    "        if \"m20\" in par_name:\n",
    "            c = \"#EB984E\"\n",
    "        if \"c5\" in par_name:\n",
    "            m = \"*\"\n",
    "            ms = 15\n",
    "        if \"c10\" in par_name:\n",
    "            m = \"^\"\n",
    "            ms = 10\n",
    "        if \"c20\" in par_name:\n",
    "            m = \"s\"\n",
    "            ms = 10\n",
    "        if \"c50\" in par_name:\n",
    "            m = \"o\"\n",
    "            ms = 10\n",
    "        \n",
    "        \n",
    "        plt.plot(x_nbr_cpg_vals, y_cohens_d_vals, linestyle=\"-\", color=c, marker=m, markersize=ms, label=par_name)\n",
    "    \n",
    "    \n",
    "    plt.axhline(y=0.2, linewidth=1, color = '#2C3E50',linestyle='--')\n",
    "    plt.axhline(y=0.5, linewidth=1, color = '#2C3E50',linestyle='--')\n",
    "    plt.axhline(y=0.8, linewidth=1, color = '#2C3E50',linestyle='--')\n",
    "    \n",
    "    e = 0.02\n",
    "    ax.text(-1.8,0.2+e, \"Small ES\")\n",
    "    ax.text(-1.8,0.5+e, \"Medium ES\")\n",
    "    ax.text(-1.8,0.8+e, \"Large ES\")\n",
    "\n",
    "    ax.set_ylabel(\"Cohen's D\", fontsize=22)\n",
    "    ax.set_xlabel(\"Number of CpGs in sliding window\", fontsize=22)   \n",
    "\n",
    "    plt.xlim(-2,30)\n",
    "    plt.ylim(-5,5)\n",
    "    plt.xticks(fontsize=18)\n",
    "    plt.yticks(fontsize=18)\n",
    "\n",
    "    legend = ax.legend(loc=\"lower left\", ncol=4, frameon = 1, prop={'size':18})\n",
    "    legend.get_frame().set_facecolor('white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_nbr_CpGs_cohensd(df_NDR_pvalues, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_nbr_CpGs_cohensd(df_NOR_pvalues, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pvals_cohensd(df_values,params):\n",
    "    \n",
    "    plt.figure(figsize=(15,7))\n",
    "    ax = plt.subplot(1,1,1)\n",
    "    \n",
    "    nbr_CpGs_list = sorted(list(set(list(df_values[\"nbr_CpGs\"]))))\n",
    "    \n",
    "    for par_name in params:\n",
    "        df_values_tmp = df_values.loc[df_values[\"parameter\"] == par_name]\n",
    "        \n",
    "        x_nbr_cpg_vals = list(df_values_tmp[\"nbr_CpGs\"])\n",
    "        y_pvals_vals = list(df_values_tmp[\"pval_ranksums\"])\n",
    "        \n",
    "        y_pvals_log = [-np.log10(p_val) if p_val != 0.0 else 310 for p_val in y_pvals_vals]\n",
    "        # print(min([p_val for p_val in y_pvals_vals]))\n",
    "        # y_pvals_log = [-np.log10(p_val) for p_val in y_pvals_vals]\n",
    "        \n",
    "        if \"m0\" in par_name:\n",
    "            c = \"#117A65\"\n",
    "        if \"m10\" in par_name:\n",
    "            c = \"#45B39D\"\n",
    "        if \"m20\" in par_name:\n",
    "            c = \"#EB984E\"\n",
    "        if \"c5\" in par_name:\n",
    "            m = \"*\"\n",
    "            ms = 15\n",
    "        if \"c10\" in par_name:\n",
    "            m = \"^\"\n",
    "            ms = 10\n",
    "        if \"c20\" in par_name:\n",
    "            m = \"s\"\n",
    "            ms = 10\n",
    "        if \"c50\" in par_name:\n",
    "            m = \"o\"\n",
    "            ms = 10\n",
    "        \n",
    "        \n",
    "        plt.plot(x_nbr_cpg_vals,y_pvals_log,linestyle=\"-\",color=c,marker=m,markersize=ms,label=par_name)\n",
    "    \n",
    "    \n",
    "    #plt.axhline(y=-np.log10(0.05), linewidth=1, color = '#5D6D7E',linestyle='-')\n",
    "    #plt.axhline(y=-np.log10(0.01), linewidth=1, color = '#515A5A',linestyle='-')\n",
    "\n",
    "    ax.set_ylabel(\"-log10(P-value)\", fontsize=22)\n",
    "    ax.set_xlabel(\"Number of CpGs in sliding window\", fontsize=22)   \n",
    "\n",
    "    plt.xlim(-2, 30)\n",
    "    plt.ylim(0, 450)\n",
    "    plt.xticks(fontsize=18)\n",
    "    plt.yticks(fontsize=18)\n",
    "\n",
    "    legend = ax.legend(loc=\"upper right\",ncol=4,frameon = 1,prop={'size':18})\n",
    "    legend.get_frame().set_facecolor('white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pvals_cohensd(df_NDR_pvalues, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pvals_cohensd(df_NOR_pvalues, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cohen's D Calculation Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from scipy import stats\n",
    "\n",
    "def calculate_cohens_d(list_EXP,list_RAND):\n",
    "    mEXP = np.mean(list_EXP)\n",
    "    sdEXP = np.std(list_EXP)\n",
    "    \n",
    "    mRAND = np.mean(list_RAND)\n",
    "    sdRAND = np.std(list_RAND)\n",
    "    \n",
    "    denom = np.sqrt(float(sdEXP**2 + sdRAND**2)/2.0)\n",
    "    cohens_d = float(mEXP-mRAND)/float(denom + 1e-6)\n",
    "    \n",
    "    return cohens_d\n",
    "\n",
    "def make_df_cohens_d(df_scores_EXP, df_scores_RAND, params):\n",
    "    column_names = [\"parameter\", \"N_EXP\", \"N_RAND\", \"mean_EXP\", \"median_EXP\", \"std_EXP\", \"mean_RAND\",\n",
    "                    \"median_RAND\", \"std_RAND\", \"cohens_d\", \"is_normal_EXP\", \"is_normal_RAND\", \"pval_ttest\",\n",
    "                    \"t_stat\", \"pval_ranksums\", \"pval_ks_2samp\"]\n",
    "    info_dict = dict()\n",
    "    for col in column_names:\n",
    "        info_dict[col] = []\n",
    "    \n",
    "    df_scores_EXP_tmp = df_scores_EXP.loc[df_scores_EXP['nbr_CpGs'].between(10,20)]\n",
    "    df_scores_RAND_tmp = df_scores_RAND.loc[df_scores_RAND['nbr_CpGs'].between(10,20)]\n",
    "                    \n",
    "    for p in range(len(params)):\n",
    "        par_name = params[p]\n",
    "        EXP_scores = list(df_scores_EXP_tmp[par_name])\n",
    "        RAND_scores = list(df_scores_RAND_tmp[par_name])\n",
    "        \n",
    "        # info_dict[\"nbr_CpGs\"].append(nbr_CpGs)\n",
    "        info_dict[\"parameter\"].append(par_name)\n",
    "        \n",
    "        info_dict[\"N_EXP\"].append(len(EXP_scores))\n",
    "        info_dict[\"N_RAND\"].append(len(RAND_scores))\n",
    "        \n",
    "        info_dict[\"mean_EXP\"].append(np.mean(EXP_scores))\n",
    "        info_dict[\"median_EXP\"].append(np.median(EXP_scores))\n",
    "        info_dict[\"std_EXP\"].append(np.std(EXP_scores))\n",
    "        \n",
    "        info_dict[\"mean_RAND\"].append(np.mean(RAND_scores))\n",
    "        info_dict[\"median_RAND\"].append(np.median(RAND_scores))\n",
    "        info_dict[\"std_RAND\"].append(np.std(RAND_scores))\n",
    "        \n",
    "        #EFFECT SIZE\n",
    "        cohens_d = calculate_cohens_d(EXP_scores, RAND_scores)\n",
    "        info_dict[\"cohens_d\"].append(cohens_d)\n",
    "        \n",
    "        #STAT TESTS\n",
    "        #is normal distributed? This function tests the null hypothesis that a sample comes from a normal distribution. If small -> ost likely not normal dustributed\n",
    "        pval_normal_EXP = stats.normaltest(EXP_scores)[1] if len(EXP_scores) >= 8 else -1\n",
    "        pval_normal_RAND = stats.normaltest(RAND_scores)[1] if len(EXP_scores) >= 8 else -1\n",
    "        \n",
    "        #students t\n",
    "        ttest_res = stats.ttest_ind(EXP_scores,RAND_scores,equal_var = False)\n",
    "        t_stat = ttest_res[0]\n",
    "        p_val_ttest = float(ttest_res[1])/2.0\n",
    "        \n",
    "        #ranksums, kstest\n",
    "        ranksums = scipy.stats.ranksums(EXP_scores,RAND_scores)[1]\n",
    "        ks_2samp = scipy.stats.ks_2samp(EXP_scores,RAND_scores)[1]\n",
    "\n",
    "        info_dict[\"is_normal_EXP\"].append(pval_normal_EXP)\n",
    "        info_dict[\"is_normal_RAND\"].append(pval_normal_RAND)\n",
    "        info_dict[\"pval_ttest\"].append(p_val_ttest)\n",
    "        info_dict[\"t_stat\"].append(t_stat)\n",
    "        info_dict[\"pval_ranksums\"].append(ranksums)\n",
    "        info_dict[\"pval_ks_2samp\"].append(ks_2samp)\n",
    "            \n",
    "    #Built dataframe\n",
    "    df = pd.DataFrame(0, index = np.arange(len(info_dict[\"parameter\"])),columns = column_names)\n",
    "    for feat in column_names:\n",
    "        df[feat] = info_dict[feat]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# region = 'promoter'\n",
    "# region = 'intron.1.start'\n",
    "# region = 'intron.1.end'\n",
    "# region = 'intron.2.start'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_NDR_score_exp = pd.read_csv(sliding_path / f'{region}.df_NDR_score_exp.csv')\n",
    "# df_NDR_score_random = pd.read_csv(sliding_path / f'{region}.df_NDR_score_random.csv')\n",
    "# df_NOR_score_exp = pd.read_csv(sliding_path / f'{region}.df_NOR_score_exp.csv')\n",
    "# df_NOR_score_random = pd.read_csv(sliding_path / f'{region}.df_NOR_score_random.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_NDR_pvalues = make_df_cohens_d(df_NDR_score_exp, df_NDR_score_random, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_NOR_pvalues = make_df_cohens_d(df_NOR_score_exp, df_NOR_score_random, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_NDR_pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_NOR_pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "promoter\n",
      "intron.1.start\n",
      "intron.1.end\n",
      "intron.2.start\n"
     ]
    }
   ],
   "source": [
    "regions = ['promoter', 'intron.1.start', 'intron.1.end', 'intron.2.start']\n",
    "labels = ['promoter', 'start of 1st intron', 'end of 1st intron', 'start of 2nd intron']\n",
    "table = {}\n",
    "for label, region in zip(labels, regions):\n",
    "    print(region)\n",
    "    df_NDR_score_exp = pd.read_csv(sliding_path / f'{region}.df_NDR_score_exp.csv')\n",
    "    df_NDR_score_random = pd.read_csv(sliding_path / f'{region}.df_NDR_score_random.csv')\n",
    "    df_NOR_score_exp = pd.read_csv(sliding_path / f'{region}.df_NOR_score_exp.csv')\n",
    "    df_NOR_score_random = pd.read_csv(sliding_path / f'{region}.df_NOR_score_random.csv')\n",
    "\n",
    "    df_NDR_pvalues = make_df_cohens_d(df_NDR_score_exp, df_NDR_score_random, params)\n",
    "    df_NOR_pvalues = make_df_cohens_d(df_NOR_score_exp, df_NOR_score_random, params)\n",
    "\n",
    "    assert df_NDR_pvalues.shape[0] == df_NOR_pvalues.shape[0]\n",
    "    assert df_NDR_pvalues['parameter'].to_list() == df_NOR_pvalues['parameter'].to_list()\n",
    "\n",
    "    table[label] = {\n",
    "        'Parameter': df_NDR_pvalues['parameter'].to_list(),\n",
    "        'HNDRs': df_NOR_pvalues['cohens_d'].to_list(),\n",
    "        'LNDRs': df_NDR_pvalues['cohens_d'].to_list()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_table = pd.DataFrame(table).T.explode(['Parameter', 'LNDRs', 'HNDRs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameter</th>\n",
       "      <th>HNDRs</th>\n",
       "      <th>LNDRs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>promoter</th>\n",
       "      <td>c5m0</td>\n",
       "      <td>0.844334</td>\n",
       "      <td>0.392026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>promoter</th>\n",
       "      <td>c5m10</td>\n",
       "      <td>0.845001</td>\n",
       "      <td>0.390944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>promoter</th>\n",
       "      <td>c5m20</td>\n",
       "      <td>0.864478</td>\n",
       "      <td>0.44387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>promoter</th>\n",
       "      <td>c10m0</td>\n",
       "      <td>0.46329</td>\n",
       "      <td>0.216024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>promoter</th>\n",
       "      <td>c10m10</td>\n",
       "      <td>0.463641</td>\n",
       "      <td>0.215351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>promoter</th>\n",
       "      <td>c10m20</td>\n",
       "      <td>0.474219</td>\n",
       "      <td>0.243697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>promoter</th>\n",
       "      <td>c20m0</td>\n",
       "      <td>-0.270655</td>\n",
       "      <td>-0.128855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>promoter</th>\n",
       "      <td>c20m10</td>\n",
       "      <td>-0.270592</td>\n",
       "      <td>-0.128918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>promoter</th>\n",
       "      <td>c20m20</td>\n",
       "      <td>-0.273856</td>\n",
       "      <td>-0.146388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>promoter</th>\n",
       "      <td>c50m0</td>\n",
       "      <td>-1.395537</td>\n",
       "      <td>-0.652403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>promoter</th>\n",
       "      <td>c50m10</td>\n",
       "      <td>-1.396433</td>\n",
       "      <td>-0.652053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>promoter</th>\n",
       "      <td>c50m20</td>\n",
       "      <td>-1.433688</td>\n",
       "      <td>-0.737705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start of 1st intron</th>\n",
       "      <td>c5m0</td>\n",
       "      <td>1.205436</td>\n",
       "      <td>0.647242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start of 1st intron</th>\n",
       "      <td>c5m10</td>\n",
       "      <td>1.20527</td>\n",
       "      <td>0.647893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start of 1st intron</th>\n",
       "      <td>c5m20</td>\n",
       "      <td>1.244542</td>\n",
       "      <td>0.700976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start of 1st intron</th>\n",
       "      <td>c10m0</td>\n",
       "      <td>0.673438</td>\n",
       "      <td>0.36305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start of 1st intron</th>\n",
       "      <td>c10m10</td>\n",
       "      <td>0.673346</td>\n",
       "      <td>0.363544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start of 1st intron</th>\n",
       "      <td>c10m20</td>\n",
       "      <td>0.695608</td>\n",
       "      <td>0.390872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start of 1st intron</th>\n",
       "      <td>c20m0</td>\n",
       "      <td>-0.379987</td>\n",
       "      <td>-0.21736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start of 1st intron</th>\n",
       "      <td>c20m10</td>\n",
       "      <td>-0.379376</td>\n",
       "      <td>-0.217731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start of 1st intron</th>\n",
       "      <td>c20m20</td>\n",
       "      <td>-0.395277</td>\n",
       "      <td>-0.238342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start of 1st intron</th>\n",
       "      <td>c50m0</td>\n",
       "      <td>-1.909674</td>\n",
       "      <td>-1.049337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start of 1st intron</th>\n",
       "      <td>c50m10</td>\n",
       "      <td>-1.908066</td>\n",
       "      <td>-1.051258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start of 1st intron</th>\n",
       "      <td>c50m20</td>\n",
       "      <td>-1.97714</td>\n",
       "      <td>-1.134768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>end of 1st intron</th>\n",
       "      <td>c5m0</td>\n",
       "      <td>1.282802</td>\n",
       "      <td>0.996352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>end of 1st intron</th>\n",
       "      <td>c5m10</td>\n",
       "      <td>1.276652</td>\n",
       "      <td>0.99559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>end of 1st intron</th>\n",
       "      <td>c5m20</td>\n",
       "      <td>1.305215</td>\n",
       "      <td>1.021143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>end of 1st intron</th>\n",
       "      <td>c10m0</td>\n",
       "      <td>0.733141</td>\n",
       "      <td>0.566358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>end of 1st intron</th>\n",
       "      <td>c10m10</td>\n",
       "      <td>0.729637</td>\n",
       "      <td>0.566435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>end of 1st intron</th>\n",
       "      <td>c10m20</td>\n",
       "      <td>0.757061</td>\n",
       "      <td>0.584822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>end of 1st intron</th>\n",
       "      <td>c20m0</td>\n",
       "      <td>-0.407737</td>\n",
       "      <td>-0.318844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>end of 1st intron</th>\n",
       "      <td>c20m10</td>\n",
       "      <td>-0.405261</td>\n",
       "      <td>-0.318776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>end of 1st intron</th>\n",
       "      <td>c20m20</td>\n",
       "      <td>-0.417707</td>\n",
       "      <td>-0.335574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>end of 1st intron</th>\n",
       "      <td>c50m0</td>\n",
       "      <td>-1.92797</td>\n",
       "      <td>-1.504829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>end of 1st intron</th>\n",
       "      <td>c50m10</td>\n",
       "      <td>-1.917533</td>\n",
       "      <td>-1.502271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>end of 1st intron</th>\n",
       "      <td>c50m20</td>\n",
       "      <td>-1.928159</td>\n",
       "      <td>-1.531141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start of 2nd intron</th>\n",
       "      <td>c5m0</td>\n",
       "      <td>1.371871</td>\n",
       "      <td>0.968847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start of 2nd intron</th>\n",
       "      <td>c5m10</td>\n",
       "      <td>1.370688</td>\n",
       "      <td>0.968911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start of 2nd intron</th>\n",
       "      <td>c5m20</td>\n",
       "      <td>1.402945</td>\n",
       "      <td>1.006121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start of 2nd intron</th>\n",
       "      <td>c10m0</td>\n",
       "      <td>0.744888</td>\n",
       "      <td>0.548267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start of 2nd intron</th>\n",
       "      <td>c10m10</td>\n",
       "      <td>0.744288</td>\n",
       "      <td>0.548475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start of 2nd intron</th>\n",
       "      <td>c10m20</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.570652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start of 2nd intron</th>\n",
       "      <td>c20m0</td>\n",
       "      <td>-0.412525</td>\n",
       "      <td>-0.304149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start of 2nd intron</th>\n",
       "      <td>c20m10</td>\n",
       "      <td>-0.412357</td>\n",
       "      <td>-0.304182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start of 2nd intron</th>\n",
       "      <td>c20m20</td>\n",
       "      <td>-0.428069</td>\n",
       "      <td>-0.322696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start of 2nd intron</th>\n",
       "      <td>c50m0</td>\n",
       "      <td>-2.244469</td>\n",
       "      <td>-1.481249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start of 2nd intron</th>\n",
       "      <td>c50m10</td>\n",
       "      <td>-2.243199</td>\n",
       "      <td>-1.480993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start of 2nd intron</th>\n",
       "      <td>c50m20</td>\n",
       "      <td>-2.300333</td>\n",
       "      <td>-1.535678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Parameter     HNDRs     LNDRs\n",
       "promoter                 c5m0  0.844334  0.392026\n",
       "promoter                c5m10  0.845001  0.390944\n",
       "promoter                c5m20  0.864478   0.44387\n",
       "promoter                c10m0   0.46329  0.216024\n",
       "promoter               c10m10  0.463641  0.215351\n",
       "promoter               c10m20  0.474219  0.243697\n",
       "promoter                c20m0 -0.270655 -0.128855\n",
       "promoter               c20m10 -0.270592 -0.128918\n",
       "promoter               c20m20 -0.273856 -0.146388\n",
       "promoter                c50m0 -1.395537 -0.652403\n",
       "promoter               c50m10 -1.396433 -0.652053\n",
       "promoter               c50m20 -1.433688 -0.737705\n",
       "start of 1st intron      c5m0  1.205436  0.647242\n",
       "start of 1st intron     c5m10   1.20527  0.647893\n",
       "start of 1st intron     c5m20  1.244542  0.700976\n",
       "start of 1st intron     c10m0  0.673438   0.36305\n",
       "start of 1st intron    c10m10  0.673346  0.363544\n",
       "start of 1st intron    c10m20  0.695608  0.390872\n",
       "start of 1st intron     c20m0 -0.379987  -0.21736\n",
       "start of 1st intron    c20m10 -0.379376 -0.217731\n",
       "start of 1st intron    c20m20 -0.395277 -0.238342\n",
       "start of 1st intron     c50m0 -1.909674 -1.049337\n",
       "start of 1st intron    c50m10 -1.908066 -1.051258\n",
       "start of 1st intron    c50m20  -1.97714 -1.134768\n",
       "end of 1st intron        c5m0  1.282802  0.996352\n",
       "end of 1st intron       c5m10  1.276652   0.99559\n",
       "end of 1st intron       c5m20  1.305215  1.021143\n",
       "end of 1st intron       c10m0  0.733141  0.566358\n",
       "end of 1st intron      c10m10  0.729637  0.566435\n",
       "end of 1st intron      c10m20  0.757061  0.584822\n",
       "end of 1st intron       c20m0 -0.407737 -0.318844\n",
       "end of 1st intron      c20m10 -0.405261 -0.318776\n",
       "end of 1st intron      c20m20 -0.417707 -0.335574\n",
       "end of 1st intron       c50m0  -1.92797 -1.504829\n",
       "end of 1st intron      c50m10 -1.917533 -1.502271\n",
       "end of 1st intron      c50m20 -1.928159 -1.531141\n",
       "start of 2nd intron      c5m0  1.371871  0.968847\n",
       "start of 2nd intron     c5m10  1.370688  0.968911\n",
       "start of 2nd intron     c5m20  1.402945  1.006121\n",
       "start of 2nd intron     c10m0  0.744888  0.548267\n",
       "start of 2nd intron    c10m10  0.744288  0.548475\n",
       "start of 2nd intron    c10m20  0.766082  0.570652\n",
       "start of 2nd intron     c20m0 -0.412525 -0.304149\n",
       "start of 2nd intron    c20m10 -0.412357 -0.304182\n",
       "start of 2nd intron    c20m20 -0.428069 -0.322696\n",
       "start of 2nd intron     c50m0 -2.244469 -1.481249\n",
       "start of 2nd intron    c50m10 -2.243199 -1.480993\n",
       "start of 2nd intron    c50m20 -2.300333 -1.535678"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llll}\n",
      "\\toprule\n",
      "{} & Parameter & HNDRs & LNDRs \\\\\n",
      "\\midrule\n",
      "promoter            &      c5m0 &  0.84 &  0.39 \\\\\n",
      "promoter            &     c5m10 &  0.85 &  0.39 \\\\\n",
      "promoter            &     c5m20 &  0.86 &  0.44 \\\\\n",
      "promoter            &     c10m0 &  0.46 &  0.22 \\\\\n",
      "promoter            &    c10m10 &  0.46 &  0.22 \\\\\n",
      "promoter            &    c10m20 &  0.47 &  0.24 \\\\\n",
      "promoter            &     c20m0 & -0.27 & -0.13 \\\\\n",
      "promoter            &    c20m10 & -0.27 & -0.13 \\\\\n",
      "promoter            &    c20m20 & -0.27 & -0.15 \\\\\n",
      "promoter            &     c50m0 & -1.40 & -0.65 \\\\\n",
      "promoter            &    c50m10 & -1.40 & -0.65 \\\\\n",
      "promoter            &    c50m20 & -1.43 & -0.74 \\\\\n",
      "start of 1st intron &      c5m0 &  1.21 &  0.65 \\\\\n",
      "start of 1st intron &     c5m10 &  1.21 &  0.65 \\\\\n",
      "start of 1st intron &     c5m20 &  1.24 &  0.70 \\\\\n",
      "start of 1st intron &     c10m0 &  0.67 &  0.36 \\\\\n",
      "start of 1st intron &    c10m10 &  0.67 &  0.36 \\\\\n",
      "start of 1st intron &    c10m20 &  0.70 &  0.39 \\\\\n",
      "start of 1st intron &     c20m0 & -0.38 & -0.22 \\\\\n",
      "start of 1st intron &    c20m10 & -0.38 & -0.22 \\\\\n",
      "start of 1st intron &    c20m20 & -0.40 & -0.24 \\\\\n",
      "start of 1st intron &     c50m0 & -1.91 & -1.05 \\\\\n",
      "start of 1st intron &    c50m10 & -1.91 & -1.05 \\\\\n",
      "start of 1st intron &    c50m20 & -1.98 & -1.13 \\\\\n",
      "end of 1st intron   &      c5m0 &  1.28 &  1.00 \\\\\n",
      "end of 1st intron   &     c5m10 &  1.28 &  1.00 \\\\\n",
      "end of 1st intron   &     c5m20 &  1.31 &  1.02 \\\\\n",
      "end of 1st intron   &     c10m0 &  0.73 &  0.57 \\\\\n",
      "end of 1st intron   &    c10m10 &  0.73 &  0.57 \\\\\n",
      "end of 1st intron   &    c10m20 &  0.76 &  0.58 \\\\\n",
      "end of 1st intron   &     c20m0 & -0.41 & -0.32 \\\\\n",
      "end of 1st intron   &    c20m10 & -0.41 & -0.32 \\\\\n",
      "end of 1st intron   &    c20m20 & -0.42 & -0.34 \\\\\n",
      "end of 1st intron   &     c50m0 & -1.93 & -1.50 \\\\\n",
      "end of 1st intron   &    c50m10 & -1.92 & -1.50 \\\\\n",
      "end of 1st intron   &    c50m20 & -1.93 & -1.53 \\\\\n",
      "start of 2nd intron &      c5m0 &  1.37 &  0.97 \\\\\n",
      "start of 2nd intron &     c5m10 &  1.37 &  0.97 \\\\\n",
      "start of 2nd intron &     c5m20 &  1.40 &  1.01 \\\\\n",
      "start of 2nd intron &     c10m0 &  0.74 &  0.55 \\\\\n",
      "start of 2nd intron &    c10m10 &  0.74 &  0.55 \\\\\n",
      "start of 2nd intron &    c10m20 &  0.77 &  0.57 \\\\\n",
      "start of 2nd intron &     c20m0 & -0.41 & -0.30 \\\\\n",
      "start of 2nd intron &    c20m10 & -0.41 & -0.30 \\\\\n",
      "start of 2nd intron &    c20m20 & -0.43 & -0.32 \\\\\n",
      "start of 2nd intron &     c50m0 & -2.24 & -1.48 \\\\\n",
      "start of 2nd intron &    c50m10 & -2.24 & -1.48 \\\\\n",
      "start of 2nd intron &    c50m20 & -2.30 & -1.54 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3784297/2883573959.py:1: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(df_table.to_latex(float_format=\"{:.2f}\".format))\n"
     ]
    }
   ],
   "source": [
    "print(df_table.to_latex(float_format=\"{:.2f}\".format))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameter</th>\n",
       "      <th>HNDRs</th>\n",
       "      <th>LNDRs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>promoter</th>\n",
       "      <td>c5m0</td>\n",
       "      <td>0.844334</td>\n",
       "      <td>0.392026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>promoter</th>\n",
       "      <td>c5m10</td>\n",
       "      <td>0.845001</td>\n",
       "      <td>0.390944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>promoter</th>\n",
       "      <td>c5m20</td>\n",
       "      <td>0.864478</td>\n",
       "      <td>0.44387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start of 1st intron</th>\n",
       "      <td>c5m0</td>\n",
       "      <td>1.205436</td>\n",
       "      <td>0.647242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start of 1st intron</th>\n",
       "      <td>c5m10</td>\n",
       "      <td>1.20527</td>\n",
       "      <td>0.647893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start of 1st intron</th>\n",
       "      <td>c5m20</td>\n",
       "      <td>1.244542</td>\n",
       "      <td>0.700976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>end of 1st intron</th>\n",
       "      <td>c5m0</td>\n",
       "      <td>1.282802</td>\n",
       "      <td>0.996352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>end of 1st intron</th>\n",
       "      <td>c5m10</td>\n",
       "      <td>1.276652</td>\n",
       "      <td>0.99559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>end of 1st intron</th>\n",
       "      <td>c5m20</td>\n",
       "      <td>1.305215</td>\n",
       "      <td>1.021143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start of 2nd intron</th>\n",
       "      <td>c5m0</td>\n",
       "      <td>1.371871</td>\n",
       "      <td>0.968847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start of 2nd intron</th>\n",
       "      <td>c5m10</td>\n",
       "      <td>1.370688</td>\n",
       "      <td>0.968911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start of 2nd intron</th>\n",
       "      <td>c5m20</td>\n",
       "      <td>1.402945</td>\n",
       "      <td>1.006121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Parameter     HNDRs     LNDRs\n",
       "promoter                 c5m0  0.844334  0.392026\n",
       "promoter                c5m10  0.845001  0.390944\n",
       "promoter                c5m20  0.864478   0.44387\n",
       "start of 1st intron      c5m0  1.205436  0.647242\n",
       "start of 1st intron     c5m10   1.20527  0.647893\n",
       "start of 1st intron     c5m20  1.244542  0.700976\n",
       "end of 1st intron        c5m0  1.282802  0.996352\n",
       "end of 1st intron       c5m10  1.276652   0.99559\n",
       "end of 1st intron       c5m20  1.305215  1.021143\n",
       "start of 2nd intron      c5m0  1.371871  0.968847\n",
       "start of 2nd intron     c5m10  1.370688  0.968911\n",
       "start of 2nd intron     c5m20  1.402945  1.006121"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_table[df_table['Parameter'].isin(['c5m0', 'c5m10', 'c5m20'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = 'promoter'\n",
    "# region = 'intron.1.start'\n",
    "# region = 'intron.1.end'\n",
    "# region = 'intron.2.start'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NDR_score_exp = pd.read_csv(sliding_path / f'{region}.df_NDR_score_exp.csv')\n",
    "df_NDR_score_random = pd.read_csv(sliding_path / f'{region}.df_NDR_score_random.csv')\n",
    "df_NOR_score_exp = pd.read_csv(sliding_path / f'{region}.df_NOR_score_exp.csv')\n",
    "df_NOR_score_random = pd.read_csv(sliding_path / f'{region}.df_NOR_score_random.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NDR_score_exp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 4, figsize=(20,12), layout='constrained')\n",
    "order = ['c5m0', 'c10m0', 'c20m0', 'c50m0', 'c5m10', 'c10m10', 'c20m10', 'c50m10', 'c5m20', 'c10m20', 'c20m20', 'c50m20']\n",
    "\n",
    "for ax, thresh in zip(axs.flatten(), order):\n",
    "    ax.hist(df_NDR_score_random.loc[df_NDR_score_random['nbr_CpGs'].between(10,20), thresh], density=True, alpha=0.5, bins=np.linspace(0,1,20), label='random')\n",
    "    ax.hist(df_NDR_score_exp.loc[df_NDR_score_exp['nbr_CpGs'].between(10,20), thresh], density=True, alpha=0.3, bins=np.linspace(0,1,20), label='experimental')\n",
    "    ax.set_title(thresh, fontsize=20)\n",
    "    ax.set_xlabel('match-score', fontsize=16)\n",
    "    ax.set_ylabel('density', fontsize=16)\n",
    "    ax.legend(fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 4, figsize=(20,12), layout='constrained')\n",
    "order = ['c5m0', 'c10m0', 'c20m0', 'c50m0', 'c5m10', 'c10m10', 'c20m10', 'c50m10', 'c5m20', 'c10m20', 'c20m20', 'c50m20']\n",
    "\n",
    "for ax, thresh in zip(axs.flatten(), order):\n",
    "    ax.hist(df_NOR_score_random.loc[df_NOR_score_random['nbr_CpGs'].between(10,20), thresh], density=True, alpha=0.5, bins=np.linspace(0,1,20), label='random')\n",
    "    ax.hist(df_NOR_score_exp.loc[df_NOR_score_exp['nbr_CpGs'].between(10,20), thresh], density=True, alpha=0.3, bins=np.linspace(0,1,20), label='experimental')\n",
    "    ax.set_title(thresh, fontsize=20)\n",
    "    ax.set_xlabel('match-score', fontsize=16)\n",
    "    ax.set_ylabel('density', fontsize=16)\n",
    "    ax.legend(fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "helms-lab-jupyter",
   "language": "python",
   "name": "helms-lab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
