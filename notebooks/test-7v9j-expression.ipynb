{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from workspace import nometools as nome\n",
    "from workspace import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_path = Path('..')\n",
    "data_path = main_path / 'Data'\n",
    "steric_path = main_path / 'superposition' / 'clash_7V9J'\n",
    "intersect_path = main_path / 'Data' / 'intersect_regions'\n",
    "sliding_path = main_path / 'Data' / 'sliding_window_7v9j'\n",
    "\n",
    "ref_path = data_path / 'GRCh38genome'\n",
    "transcriptome_path = data_path / 'transcriptome'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize Steric Clash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = steric_path / 'x_y_dict'\n",
    "with open(infile, 'rb') as fin:\n",
    "    x_y_clash_dict = pickle.load(fin)\n",
    "\n",
    "x_y_clash_dict_norm_ = utils.normalize_clash_dict(x_y_clash_dict)\n",
    "\n",
    "meth_thres_range = [0, 10, 20]\n",
    "clash_thres_range = [5, 10, 20, 50]\n",
    "\n",
    "params = []\n",
    "for clash_thres in clash_thres_range:\n",
    "    for meth_thres in meth_thres_range:\n",
    "        k = \"c\" + str(clash_thres) + \"m\" + str(meth_thres)\n",
    "        params.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_y_clash_dict.values(), marker='o')\n",
    "plt.plot(x_y_clash_dict_norm_.values(), marker='o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list(x_y_clash_dict.keys())\n",
    "y = list(x_y_clash_dict.values())\n",
    "\n",
    "fig = plt.figure(figsize=(18, 7))\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "#plt.title('Superposition of DNMT1 (3PTA) and the nucleosome (1KX5)')\n",
    "# print(sum(np.array(y) < 5))\n",
    "ax.plot(x, y, linestyle=\"-\", marker=\"o\", linewidth=2)\n",
    "# ax.plot(np.array(x)[np.array(y) < 5], np.array(y)[np.array(y) < 5], '*', color='red')\n",
    "for pos in range(0,len(x)):\n",
    "    #ax.text(x[pos]+0.3,y[pos],rmsd_list[pos])\n",
    "    ax.text(x[pos]+0.2, y[pos]+0.7, x[pos], fontsize=12)\n",
    "    \n",
    "plt.xlim(0,140)\n",
    "plt.xticks(range(0,len(x)+5,5), fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xlabel(\"Nucleosome position [bp]\", fontsize=18)\n",
    "plt.ylabel(\"DNMT1 atoms clashing [%]\", fontsize=18)\n",
    "plt.ylim(top=100)\n",
    "\n",
    "ax.axvline(x=74,c=\"grey\",linewidth=2,linestyle=\"--\")#4169e1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x_y_clash_dict.keys()), len(x_y_clash_dict_norm_.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expression and Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expression = pd.read_csv(transcriptome_path / 'LTC_HepG2_MonoCal_FA.rep1.TPM.txt', sep='\\t', names=['id', 'expression'], header=0)\n",
    "df_expression['gene_id'] = df_expression['id'].str.split(':').str[0]\n",
    "df_expression.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_expression = pd.read_csv(transcriptome_path / 'GSM2343347.tsv', sep='\\t')\n",
    "# df_expression.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(ref_path / 'transcript_to_gene.json', 'r') as file:\n",
    "    transcript_to_gene = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_to_transcript = {v.split('.')[0]:k for k,v in transcript_to_gene.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_to_transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_expressed = df_expression['expression'] > 0\n",
    "transcript_expressed = [gene_to_transcript[gene] for gene in df_expression.loc[mask_expressed, 'gene_id'] if gene in gene_to_transcript]\n",
    "transcript_not_expressed = [gene_to_transcript[gene] for gene in df_expression.loc[~mask_expressed, 'gene_id'] if gene in gene_to_transcript]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(transcript_expressed), len(transcript_not_expressed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cohen's D and P values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from scipy import stats\n",
    "\n",
    "def calculate_cohens_d(list_EXP,list_RAND):\n",
    "    mEXP = np.mean(list_EXP)\n",
    "    sdEXP = np.std(list_EXP)\n",
    "    \n",
    "    mRAND = np.mean(list_RAND)\n",
    "    sdRAND = np.std(list_RAND)\n",
    "    \n",
    "    denom = np.sqrt(float(sdEXP**2 + sdRAND**2)/2.0)\n",
    "    cohens_d = float(mEXP-mRAND)/float(denom + 1e-6)\n",
    "    \n",
    "    return cohens_d\n",
    "\n",
    "def make_df_p_vals_cohens_d(df_scores_EXP, df_scores_RAND, params):\n",
    "    column_names = [\"nbr_CpGs\", \"parameter\", \"N_EXP\", \"N_RAND\", \"mean_EXP\", \"median_EXP\", \"std_EXP\", \"mean_RAND\",\n",
    "                    \"median_RAND\", \"std_RAND\", \"cohens_d\", \"is_normal_EXP\", \"is_normal_RAND\", \"pval_ttest\",\n",
    "                    \"t_stat\", \"pval_ranksums\", \"pval_ks_2samp\"]\n",
    "    info_dict = dict()\n",
    "    for col in column_names:\n",
    "        info_dict[col] = []\n",
    "\n",
    "    nbr_CpGs_list = list(set(list(df_scores_EXP[\"nbr_CpGs\"])))\n",
    "\n",
    "    for nbr_CpGs in nbr_CpGs_list:\n",
    "        df_scores_EXP_tmp = df_scores_EXP.loc[df_scores_EXP[\"nbr_CpGs\"] == nbr_CpGs]\n",
    "        df_scores_RAND_tmp = df_scores_RAND.loc[df_scores_RAND[\"nbr_CpGs\"] == nbr_CpGs]\n",
    "                    \n",
    "        for p in range(len(params)):\n",
    "            par_name = params[p]\n",
    "            EXP_scores = list(df_scores_EXP_tmp[par_name])\n",
    "            RAND_scores = list(df_scores_RAND_tmp[par_name])\n",
    "            \n",
    "            info_dict[\"nbr_CpGs\"].append(nbr_CpGs)\n",
    "            info_dict[\"parameter\"].append(par_name)\n",
    "            \n",
    "            info_dict[\"N_EXP\"].append(len(EXP_scores))\n",
    "            info_dict[\"N_RAND\"].append(len(RAND_scores))\n",
    "            \n",
    "            info_dict[\"mean_EXP\"].append(np.mean(EXP_scores))\n",
    "            info_dict[\"median_EXP\"].append(np.median(EXP_scores))\n",
    "            info_dict[\"std_EXP\"].append(np.std(EXP_scores))\n",
    "            \n",
    "            info_dict[\"mean_RAND\"].append(np.mean(RAND_scores))\n",
    "            info_dict[\"median_RAND\"].append(np.median(RAND_scores))\n",
    "            info_dict[\"std_RAND\"].append(np.std(RAND_scores))\n",
    "            \n",
    "            #EFFECT SIZE\n",
    "            cohens_d = calculate_cohens_d(EXP_scores, RAND_scores)\n",
    "            info_dict[\"cohens_d\"].append(cohens_d)\n",
    "            \n",
    "            #STAT TESTS\n",
    "            #is normal distributed? This function tests the null hypothesis that a sample comes from a normal distribution. If small -> ost likely not normal dustributed\n",
    "            pval_normal_EXP = stats.normaltest(EXP_scores)[1] if len(EXP_scores) >= 8 else -1\n",
    "            pval_normal_RAND = stats.normaltest(RAND_scores)[1] if len(EXP_scores) >= 8 else -1\n",
    "            \n",
    "            #students t\n",
    "            ttest_res = stats.ttest_ind(EXP_scores,RAND_scores,equal_var = False)\n",
    "            t_stat = ttest_res[0]\n",
    "            p_val_ttest = float(ttest_res[1])/2.0\n",
    "            \n",
    "            #ranksums, kstest\n",
    "            ranksums = scipy.stats.ranksums(EXP_scores,RAND_scores)[1]\n",
    "            ks_2samp = scipy.stats.ks_2samp(EXP_scores,RAND_scores)[1]\n",
    "    \n",
    "            info_dict[\"is_normal_EXP\"].append(pval_normal_EXP)\n",
    "            info_dict[\"is_normal_RAND\"].append(pval_normal_RAND)\n",
    "            info_dict[\"pval_ttest\"].append(p_val_ttest)\n",
    "            info_dict[\"t_stat\"].append(t_stat)\n",
    "            info_dict[\"pval_ranksums\"].append(ranksums)\n",
    "            info_dict[\"pval_ks_2samp\"].append(ks_2samp)\n",
    "            \n",
    "    #Built dataframe\n",
    "    df = pd.DataFrame(0, index = np.arange(len(info_dict[\"nbr_CpGs\"])),columns = column_names)\n",
    "    for feat in column_names:\n",
    "        df[feat] = info_dict[feat]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = 'promoter'\n",
    "# region = 'intron.1.start'\n",
    "# region = 'intron.1.end'\n",
    "# region = 'intron.2.start'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expression = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NDR_score_exp = pd.read_csv(sliding_path / f'{region}.df_NDR_score_exp.csv')\n",
    "df_NDR_score_random = pd.read_csv(sliding_path / f'{region}.df_NDR_score_random.csv')\n",
    "df_NOR_score_exp = pd.read_csv(sliding_path / f'{region}.df_NOR_score_exp.csv')\n",
    "df_NOR_score_random = pd.read_csv(sliding_path / f'{region}.df_NOR_score_random.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NDR_score_exp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NDR_score_exp['refid'].unique().shape, df_NOR_score_exp['refid'].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if expression:\n",
    "    df_NDR_score_exp = df_NDR_score_exp[df_NDR_score_exp['refid'].isin(transcript_expressed)]\n",
    "    df_NDR_score_random = df_NDR_score_random[df_NDR_score_random['refid'].isin(transcript_expressed)]\n",
    "    df_NOR_score_exp = df_NOR_score_exp[df_NOR_score_exp['refid'].isin(transcript_expressed)]\n",
    "    df_NOR_score_random = df_NOR_score_random[df_NOR_score_random['refid'].isin(transcript_expressed)]\n",
    "else:\n",
    "    df_NDR_score_exp = df_NDR_score_exp[df_NDR_score_exp['refid'].isin(transcript_not_expressed)]\n",
    "    df_NDR_score_random = df_NDR_score_random[df_NDR_score_random['refid'].isin(transcript_not_expressed)]\n",
    "    df_NOR_score_exp = df_NOR_score_exp[df_NOR_score_exp['refid'].isin(transcript_not_expressed)]\n",
    "    df_NOR_score_random = df_NOR_score_random[df_NOR_score_random['refid'].isin(transcript_not_expressed)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NDR_score_exp['refid'].unique().shape, df_NOR_score_exp['refid'].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NDR_pvalues = make_df_p_vals_cohens_d(df_NDR_score_exp, df_NDR_score_random, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NOR_pvalues = make_df_p_vals_cohens_d(df_NOR_score_exp, df_NOR_score_random, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NDR_pvalues.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "groups = df_NDR_pvalues.groupby(by='parameter')\n",
    "for par, df_tmp in groups:\n",
    "    plt.scatter(df_tmp['nbr_CpGs'], df_tmp['N_EXP'], label=par)\n",
    "\n",
    "# plt.axhline(y=50)\n",
    "plt.xlim(-2,30)\n",
    "# plt.ylim((10**1,10**6))\n",
    "# plt.legend()\n",
    "plt.xlabel('Number of CpGs in sliding window', fontsize=22)\n",
    "plt.ylabel('Sample size for Cohen’s D', fontsize=22)\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "groups = df_NOR_pvalues.groupby(by='parameter')\n",
    "for par, df_tmp in groups:\n",
    "    plt.scatter(df_tmp['nbr_CpGs'], df_tmp['N_EXP'], label=par)\n",
    "plt.xlim(-2,30)\n",
    "# plt.legend()\n",
    "plt.xlabel('Number of CpGs in sliding window', fontsize=22)\n",
    "plt.ylabel('Sample size for Cohen’s D', fontsize=22)\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_nbr_CpGs_cohensd(df_values, params):\n",
    "    plt.figure(figsize=(15,7))\n",
    "    ax = plt.subplot(1,1,1)\n",
    "    \n",
    "    nbr_CpGs_list = sorted(list(set(list(df_values[\"nbr_CpGs\"]))))\n",
    "\n",
    "    for par_name in params:\n",
    "        \n",
    "        df_values_tmp = df_values.loc[df_values[\"parameter\"] == par_name]\n",
    "        \n",
    "        x_nbr_cpg_vals = list(df_values_tmp[\"nbr_CpGs\"])\n",
    "        y_cohens_d_vals = list(df_values_tmp[\"cohens_d\"])\n",
    "        \n",
    "        if \"m0\" in par_name:\n",
    "            c = \"#117A65\"\n",
    "        if \"m10\" in par_name:\n",
    "            c = \"#45B39D\"\n",
    "        if \"m20\" in par_name:\n",
    "            c = \"#EB984E\"\n",
    "        if \"c5\" in par_name:\n",
    "            m = \"*\"\n",
    "            ms = 15\n",
    "        if \"c10\" in par_name:\n",
    "            m = \"^\"\n",
    "            ms = 10\n",
    "        if \"c20\" in par_name:\n",
    "            m = \"s\"\n",
    "            ms = 10\n",
    "        if \"c50\" in par_name:\n",
    "            m = \"o\"\n",
    "            ms = 10\n",
    "        \n",
    "        \n",
    "        plt.plot(x_nbr_cpg_vals, y_cohens_d_vals, linestyle=\"-\", color=c, marker=m, markersize=ms, label=par_name)\n",
    "    \n",
    "    \n",
    "    plt.axhline(y=0.2, linewidth=1, color = '#2C3E50',linestyle='--')\n",
    "    plt.axhline(y=0.5, linewidth=1, color = '#2C3E50',linestyle='--')\n",
    "    plt.axhline(y=0.8, linewidth=1, color = '#2C3E50',linestyle='--')\n",
    "    \n",
    "    e = 0.02\n",
    "    ax.text(-1.8,0.2+e, \"Small ES\")\n",
    "    ax.text(-1.8,0.5+e, \"Medium ES\")\n",
    "    ax.text(-1.8,0.8+e, \"Large ES\")\n",
    "\n",
    "    ax.set_ylabel(\"Cohen's D\", fontsize=22)\n",
    "    ax.set_xlabel(\"Number of CpGs in sliding window\", fontsize=22)   \n",
    "\n",
    "    plt.xlim(-2,30)\n",
    "    plt.ylim(-5,5)\n",
    "    plt.xticks(fontsize=18)\n",
    "    plt.yticks(fontsize=18)\n",
    "\n",
    "    legend = ax.legend(loc=\"lower left\", ncol=4, frameon = 1, prop={'size':18})\n",
    "    legend.get_frame().set_facecolor('white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_nbr_CpGs_cohensd(df_NDR_pvalues, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_nbr_CpGs_cohensd(df_NOR_pvalues, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pvals_cohensd(df_values,params):\n",
    "    \n",
    "    plt.figure(figsize=(15,7))\n",
    "    ax = plt.subplot(1,1,1)\n",
    "    \n",
    "    nbr_CpGs_list = sorted(list(set(list(df_values[\"nbr_CpGs\"]))))\n",
    "    \n",
    "    for par_name in params:\n",
    "        df_values_tmp = df_values.loc[df_values[\"parameter\"] == par_name]\n",
    "        \n",
    "        x_nbr_cpg_vals = list(df_values_tmp[\"nbr_CpGs\"])\n",
    "        y_pvals_vals = list(df_values_tmp[\"pval_ranksums\"])\n",
    "        \n",
    "        y_pvals_log = [-np.log10(p_val) if p_val != 0.0 else 310 for p_val in y_pvals_vals]\n",
    "        # print(min([p_val for p_val in y_pvals_vals]))\n",
    "        # y_pvals_log = [-np.log10(p_val) for p_val in y_pvals_vals]\n",
    "        \n",
    "        if \"m0\" in par_name:\n",
    "            c = \"#117A65\"\n",
    "        if \"m10\" in par_name:\n",
    "            c = \"#45B39D\"\n",
    "        if \"m20\" in par_name:\n",
    "            c = \"#EB984E\"\n",
    "        if \"c5\" in par_name:\n",
    "            m = \"*\"\n",
    "            ms = 15\n",
    "        if \"c10\" in par_name:\n",
    "            m = \"^\"\n",
    "            ms = 10\n",
    "        if \"c20\" in par_name:\n",
    "            m = \"s\"\n",
    "            ms = 10\n",
    "        if \"c50\" in par_name:\n",
    "            m = \"o\"\n",
    "            ms = 10\n",
    "        \n",
    "        \n",
    "        plt.plot(x_nbr_cpg_vals,y_pvals_log,linestyle=\"-\",color=c,marker=m,markersize=ms,label=par_name)\n",
    "    \n",
    "    \n",
    "    #plt.axhline(y=-np.log10(0.05), linewidth=1, color = '#5D6D7E',linestyle='-')\n",
    "    #plt.axhline(y=-np.log10(0.01), linewidth=1, color = '#515A5A',linestyle='-')\n",
    "\n",
    "    ax.set_ylabel(\"-log10(P-value)\", fontsize=22)\n",
    "    ax.set_xlabel(\"Number of CpGs in sliding window\", fontsize=22)   \n",
    "\n",
    "    plt.xlim(-2, 30)\n",
    "    plt.ylim(0, 450)\n",
    "    plt.xticks(fontsize=18)\n",
    "    plt.yticks(fontsize=18)\n",
    "\n",
    "    legend = ax.legend(loc=\"upper right\",ncol=4,frameon = 1,prop={'size':18})\n",
    "    legend.get_frame().set_facecolor('white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pvals_cohensd(df_NDR_pvalues, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pvals_cohensd(df_NOR_pvalues, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cohen's D Calculation Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from scipy import stats\n",
    "\n",
    "def calculate_cohens_d(list_EXP,list_RAND):\n",
    "    mEXP = np.mean(list_EXP)\n",
    "    sdEXP = np.std(list_EXP)\n",
    "    \n",
    "    mRAND = np.mean(list_RAND)\n",
    "    sdRAND = np.std(list_RAND)\n",
    "    \n",
    "    denom = np.sqrt(float(sdEXP**2 + sdRAND**2)/2.0)\n",
    "    cohens_d = float(mEXP-mRAND)/float(denom + 1e-6)\n",
    "    \n",
    "    return cohens_d\n",
    "\n",
    "def make_df_cohens_d(df_scores_EXP, df_scores_RAND, params):\n",
    "    column_names = [\"parameter\", \"N_EXP\", \"N_RAND\", \"mean_EXP\", \"median_EXP\", \"std_EXP\", \"mean_RAND\",\n",
    "                    \"median_RAND\", \"std_RAND\", \"cohens_d\", \"is_normal_EXP\", \"is_normal_RAND\", \"pval_ttest\",\n",
    "                    \"t_stat\", \"pval_ranksums\", \"pval_ks_2samp\"]\n",
    "    info_dict = dict()\n",
    "    for col in column_names:\n",
    "        info_dict[col] = []\n",
    "    \n",
    "    df_scores_EXP_tmp = df_scores_EXP.loc[df_scores_EXP['nbr_CpGs'].between(10,20)]\n",
    "    df_scores_RAND_tmp = df_scores_RAND.loc[df_scores_RAND['nbr_CpGs'].between(10,20)]\n",
    "                    \n",
    "    for p in range(len(params)):\n",
    "        par_name = params[p]\n",
    "        EXP_scores = list(df_scores_EXP_tmp[par_name])\n",
    "        RAND_scores = list(df_scores_RAND_tmp[par_name])\n",
    "        \n",
    "        # info_dict[\"nbr_CpGs\"].append(nbr_CpGs)\n",
    "        info_dict[\"parameter\"].append(par_name)\n",
    "        \n",
    "        info_dict[\"N_EXP\"].append(len(EXP_scores))\n",
    "        info_dict[\"N_RAND\"].append(len(RAND_scores))\n",
    "        \n",
    "        info_dict[\"mean_EXP\"].append(np.mean(EXP_scores))\n",
    "        info_dict[\"median_EXP\"].append(np.median(EXP_scores))\n",
    "        info_dict[\"std_EXP\"].append(np.std(EXP_scores))\n",
    "        \n",
    "        info_dict[\"mean_RAND\"].append(np.mean(RAND_scores))\n",
    "        info_dict[\"median_RAND\"].append(np.median(RAND_scores))\n",
    "        info_dict[\"std_RAND\"].append(np.std(RAND_scores))\n",
    "        \n",
    "        #EFFECT SIZE\n",
    "        cohens_d = calculate_cohens_d(EXP_scores, RAND_scores)\n",
    "        info_dict[\"cohens_d\"].append(cohens_d)\n",
    "        \n",
    "        #STAT TESTS\n",
    "        #is normal distributed? This function tests the null hypothesis that a sample comes from a normal distribution. If small -> ost likely not normal dustributed\n",
    "        pval_normal_EXP = stats.normaltest(EXP_scores)[1] if len(EXP_scores) >= 8 else -1\n",
    "        pval_normal_RAND = stats.normaltest(RAND_scores)[1] if len(EXP_scores) >= 8 else -1\n",
    "        \n",
    "        #students t\n",
    "        ttest_res = stats.ttest_ind(EXP_scores,RAND_scores,equal_var = False)\n",
    "        t_stat = ttest_res[0]\n",
    "        p_val_ttest = float(ttest_res[1])/2.0\n",
    "        \n",
    "        #ranksums, kstest\n",
    "        ranksums = scipy.stats.ranksums(EXP_scores,RAND_scores)[1]\n",
    "        ks_2samp = scipy.stats.ks_2samp(EXP_scores,RAND_scores)[1]\n",
    "\n",
    "        info_dict[\"is_normal_EXP\"].append(pval_normal_EXP)\n",
    "        info_dict[\"is_normal_RAND\"].append(pval_normal_RAND)\n",
    "        info_dict[\"pval_ttest\"].append(p_val_ttest)\n",
    "        info_dict[\"t_stat\"].append(t_stat)\n",
    "        info_dict[\"pval_ranksums\"].append(ranksums)\n",
    "        info_dict[\"pval_ks_2samp\"].append(ks_2samp)\n",
    "            \n",
    "    #Built dataframe\n",
    "    df = pd.DataFrame(0, index = np.arange(len(info_dict[\"parameter\"])),columns = column_names)\n",
    "    for feat in column_names:\n",
    "        df[feat] = info_dict[feat]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# region = 'promoter'\n",
    "# region = 'intron.1.start'\n",
    "# region = 'intron.1.end'\n",
    "# region = 'intron.2.start'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_NDR_score_exp = pd.read_csv(sliding_path / f'{region}.df_NDR_score_exp.csv')\n",
    "# df_NDR_score_random = pd.read_csv(sliding_path / f'{region}.df_NDR_score_random.csv')\n",
    "# df_NOR_score_exp = pd.read_csv(sliding_path / f'{region}.df_NOR_score_exp.csv')\n",
    "# df_NOR_score_random = pd.read_csv(sliding_path / f'{region}.df_NOR_score_random.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_NDR_pvalues = make_df_cohens_d(df_NDR_score_exp, df_NDR_score_random, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_NOR_pvalues = make_df_cohens_d(df_NOR_score_exp, df_NOR_score_random, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_NDR_pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_NOR_pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expression = False\n",
    "regions = ['promoter', 'intron.1.start', 'intron.1.end', 'intron.2.start']\n",
    "labels = ['promoter', 'start of 1st intron', 'end of 1st intron', 'start of 2nd intron']\n",
    "table = {}\n",
    "for label, region in zip(labels, regions):\n",
    "    print(region, expression)\n",
    "    df_NDR_score_exp = pd.read_csv(sliding_path / f'{region}.df_NDR_score_exp.csv')\n",
    "    df_NDR_score_random = pd.read_csv(sliding_path / f'{region}.df_NDR_score_random.csv')\n",
    "    df_NOR_score_exp = pd.read_csv(sliding_path / f'{region}.df_NOR_score_exp.csv')\n",
    "    df_NOR_score_random = pd.read_csv(sliding_path / f'{region}.df_NOR_score_random.csv')\n",
    "\n",
    "    if expression:\n",
    "        print(f\"NDR Exp unique transcripts: {df_NDR_score_exp['refid'].unique().shape}\")\n",
    "        df_NDR_score_exp = df_NDR_score_exp[df_NDR_score_exp['refid'].isin(transcript_expressed)]\n",
    "        print(f\"NDR Exp Expressed unique transcripts: {df_NDR_score_exp['refid'].unique().shape}\")\n",
    "\n",
    "        print(f\"NDR Rand unique transcripts: {df_NDR_score_random['refid'].unique().shape}\")\n",
    "        df_NDR_score_random = df_NDR_score_random[df_NDR_score_random['refid'].isin(transcript_expressed)]\n",
    "        print(f\"NDR Rand Expressed unique transcripts: {df_NDR_score_random['refid'].unique().shape}\")\n",
    "\n",
    "        print(f\"NOR Exp unique transcripts: {df_NOR_score_exp['refid'].unique().shape}\")\n",
    "        df_NOR_score_exp = df_NOR_score_exp[df_NOR_score_exp['refid'].isin(transcript_expressed)]\n",
    "        print(f\"NOR Exp Expressed unique transcripts: {df_NOR_score_exp['refid'].unique().shape}\")\n",
    "\n",
    "        print(f\"NOR Rand unique transcripts: {df_NOR_score_random['refid'].unique().shape}\")\n",
    "        df_NOR_score_random = df_NOR_score_random[df_NOR_score_random['refid'].isin(transcript_expressed)]\n",
    "        print(f\"NOR Rand Expressed unique transcripts: {df_NOR_score_random['refid'].unique().shape}\")\n",
    "    else:\n",
    "        print(f\"NDR Exp unique transcripts: {df_NDR_score_exp['refid'].unique().shape}\")\n",
    "        df_NDR_score_exp = df_NDR_score_exp[df_NDR_score_exp['refid'].isin(transcript_not_expressed)]\n",
    "        print(f\"NDR Exp Not Expressed unique transcripts: {df_NDR_score_exp['refid'].unique().shape}\")\n",
    "\n",
    "        print(f\"NDR Rand unique transcripts: {df_NDR_score_random['refid'].unique().shape}\")\n",
    "        df_NDR_score_random = df_NDR_score_random[df_NDR_score_random['refid'].isin(transcript_not_expressed)]\n",
    "        print(f\"NDR Rand Not Expressed unique transcripts: {df_NDR_score_random['refid'].unique().shape}\")\n",
    "\n",
    "        print(f\"NOR Exp unique transcripts: {df_NOR_score_exp['refid'].unique().shape}\")\n",
    "        df_NOR_score_exp = df_NOR_score_exp[df_NOR_score_exp['refid'].isin(transcript_not_expressed)]\n",
    "        print(f\"NOR Exp Not Expressed unique transcripts: {df_NOR_score_exp['refid'].unique().shape}\")\n",
    "\n",
    "        print(f\"NOR Rand unique transcripts: {df_NOR_score_random['refid'].unique().shape}\")\n",
    "        df_NOR_score_random = df_NOR_score_random[df_NOR_score_random['refid'].isin(transcript_not_expressed)]\n",
    "        print(f\"NOR Rand Not Expressed unique transcripts: {df_NOR_score_random['refid'].unique().shape}\")\n",
    "\n",
    "    df_NDR_pvalues = make_df_cohens_d(df_NDR_score_exp, df_NDR_score_random, params)\n",
    "    df_NOR_pvalues = make_df_cohens_d(df_NOR_score_exp, df_NOR_score_random, params)\n",
    "\n",
    "    assert df_NDR_pvalues.shape[0] == df_NOR_pvalues.shape[0]\n",
    "    assert df_NDR_pvalues['parameter'].to_list() == df_NOR_pvalues['parameter'].to_list()\n",
    "\n",
    "    table[label] = {\n",
    "        'Parameter': df_NDR_pvalues['parameter'].to_list(),\n",
    "        'HNDRs': df_NOR_pvalues['cohens_d'].to_list(),\n",
    "        'LNDRs': df_NDR_pvalues['cohens_d'].to_list()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_table = pd.DataFrame(table).T.explode(['Parameter', 'LNDRs', 'HNDRs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_table.to_latex(float_format=\"{:.2f}\".format))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_table[df_table['Parameter'].isin(['c5m0', 'c5m10', 'c5m20'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_table[df_table['Parameter'].isin(['c5m0', 'c5m10', 'c5m20'])].to_latex(float_format=\"{:.2f}\".format))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = 'promoter'\n",
    "# region = 'intron.1.start'\n",
    "# region = 'intron.1.end'\n",
    "# region = 'intron.2.start'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NDR_score_exp = pd.read_csv(sliding_path / f'{region}.df_NDR_score_exp.csv')\n",
    "df_NDR_score_random = pd.read_csv(sliding_path / f'{region}.df_NDR_score_random.csv')\n",
    "df_NOR_score_exp = pd.read_csv(sliding_path / f'{region}.df_NOR_score_exp.csv')\n",
    "df_NOR_score_random = pd.read_csv(sliding_path / f'{region}.df_NOR_score_random.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NDR_score_exp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 4, figsize=(20,12), layout='constrained')\n",
    "order = ['c5m0', 'c10m0', 'c20m0', 'c50m0', 'c5m10', 'c10m10', 'c20m10', 'c50m10', 'c5m20', 'c10m20', 'c20m20', 'c50m20']\n",
    "\n",
    "for ax, thresh in zip(axs.flatten(), order):\n",
    "    ax.hist(df_NDR_score_random.loc[df_NDR_score_random['nbr_CpGs'].between(10,20), thresh], density=True, alpha=0.5, bins=np.linspace(0,1,20), label='random')\n",
    "    ax.hist(df_NDR_score_exp.loc[df_NDR_score_exp['nbr_CpGs'].between(10,20), thresh], density=True, alpha=0.3, bins=np.linspace(0,1,20), label='experimental')\n",
    "    ax.set_title(thresh, fontsize=20)\n",
    "    ax.set_xlabel('match-score', fontsize=16)\n",
    "    ax.set_ylabel('density', fontsize=16)\n",
    "    ax.legend(fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 4, figsize=(20,12), layout='constrained')\n",
    "order = ['c5m0', 'c10m0', 'c20m0', 'c50m0', 'c5m10', 'c10m10', 'c20m10', 'c50m10', 'c5m20', 'c10m20', 'c20m20', 'c50m20']\n",
    "\n",
    "for ax, thresh in zip(axs.flatten(), order):\n",
    "    ax.hist(df_NOR_score_random.loc[df_NOR_score_random['nbr_CpGs'].between(10,20), thresh], density=True, alpha=0.5, bins=np.linspace(0,1,20), label='random')\n",
    "    ax.hist(df_NOR_score_exp.loc[df_NOR_score_exp['nbr_CpGs'].between(10,20), thresh], density=True, alpha=0.3, bins=np.linspace(0,1,20), label='experimental')\n",
    "    ax.set_title(thresh, fontsize=20)\n",
    "    ax.set_xlabel('match-score', fontsize=16)\n",
    "    ax.set_ylabel('density', fontsize=16)\n",
    "    ax.legend(fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "helms-lab-jupyter",
   "language": "python",
   "name": "helms-lab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
