{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from workspace import nometools as nome\n",
    "from workspace import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_path = Path('..')\n",
    "steric_path = main_path / 'superposition' / 'clash_7V9J'\n",
    "intersect_path = main_path / 'Data' / 'intersect_regions'\n",
    "sliding_path = main_path / 'Data' / 'sliding_window_7v9j'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize Steric Clash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = steric_path / 'x_y_dict'\n",
    "with open(infile, 'rb') as fin:\n",
    "    x_y_clash_dict = pickle.load(fin)\n",
    "\n",
    "x_y_clash_dict_norm_ = utils.normalize_clash_dict(x_y_clash_dict)\n",
    "\n",
    "meth_thres_range = [0, 10, 20]\n",
    "clash_thres_range = [5, 10, 20, 50]\n",
    "\n",
    "params = []\n",
    "for clash_thres in clash_thres_range:\n",
    "    for meth_thres in meth_thres_range:\n",
    "        k = \"c\" + str(clash_thres) + \"m\" + str(meth_thres)\n",
    "        params.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_y_clash_dict.values(), marker='o')\n",
    "plt.plot(x_y_clash_dict_norm_.values(), marker='o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_y_clash_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x_y_clash_dict.keys()), len(x_y_clash_dict_norm_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sliding Window - This remains the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# region = 'promoter'\n",
    "# region = 'intron.1.start'\n",
    "# region = 'intron.1.end'\n",
    "# region = 'intron.2.start'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# infile = intersect_path / f'{region}.NDR.HCG.intersect.bed'\n",
    "# df_NDR = nome.get_nuc_pos_methylation(infile, region=region)\n",
    "\n",
    "# infile = intersect_path / f'{region}.NDR.HCG.random.intersect.bed'\n",
    "# df_NDR_random = nome.get_nuc_pos_methylation(infile, region=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_NDR.shape, df_NDR_random.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# infile = intersect_path / f'{region}.NOR.HCG.intersect.bed'\n",
    "# df_NOR = nome.get_nuc_pos_methylation(infile, region=region)\n",
    "\n",
    "# infile = intersect_path / f'{region}.NOR.HCG.random.intersect.bed'\n",
    "# df_NOR_random = nome.get_nuc_pos_methylation(infile, region=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_NOR.shape, df_NOR_random.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_NOR.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_NDR.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_NDR_sliding_windows = nome.make_sliding_windows_file(df_NDR, x_y_clash_dict, mask=True, region=region)\n",
    "# df_NDR_sliding_windows.to_csv(sliding_path / f'{region}.df_NDR_sliding_windows.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_NDR_sliding_windows_random = nome.make_sliding_windows_file(df_NDR_random, x_y_clash_dict, region=region)\n",
    "# df_NDR_sliding_windows_random.to_csv(sliding_path / f'{region}.df_NDR_sliding_windows_random.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_NDR_sliding_windows.shape, df_NDR_sliding_windows_random.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_NOR_sliding_windows = nome.make_sliding_windows_file(df_NOR, x_y_clash_dict, region=region)\n",
    "# df_NOR_sliding_windows.to_csv(sliding_path / f'{region}.df_NOR_sliding_windows.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_NOR_sliding_windows_random = nome.make_sliding_windows_file(df_NOR_random, x_y_clash_dict, region=region)\n",
    "# df_NOR_sliding_windows_random.to_csv(sliding_path / f'{region}.df_NOR_sliding_windows_random.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_NOR_sliding_windows.shape, df_NOR_sliding_windows_random.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_NDR_sliding_windows.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_NOR_sliding_windows.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Steric Clash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "def calc_perc_exp_clash_ident(x_y_clash_dict_norm, meth_in_window_tmp, meth_thres, clash_thres):    \n",
    "    count_ident = 0\n",
    "    cpg_positions = meth_in_window_tmp.keys()\n",
    "    for meth_pos in cpg_positions:\n",
    "        meth_rate = meth_in_window_tmp[meth_pos]\n",
    "        clash_perc = x_y_clash_dict_norm[meth_pos] \n",
    "        \n",
    "        if meth_rate > meth_thres:\n",
    "            if clash_perc <= clash_thres:\n",
    "                count_ident += 1\n",
    "        else:\n",
    "            if clash_perc > clash_thres:\n",
    "                count_ident += 1\n",
    "                \n",
    "    nbr_cpgs = len(cpg_positions)\n",
    "    perc_exp_clash_ident = float(count_ident)/float(nbr_cpgs)\n",
    "    \n",
    "    return perc_exp_clash_ident\n",
    "\n",
    "def calc_score_lists(df_sliding_windows, x_y_clash_dict_norm, params):\n",
    "    column_names = [\"refid_NOR\", \"trans_id\", \"refid\", \"NOR_nbr\", \"window_nbr\", \"nbr_CpGs\", \"nuc_rel_center\", \"nuc_region_length\"] + params\n",
    "    info_dict = dict()\n",
    "    for col in column_names:\n",
    "        info_dict[col] = []\n",
    "        \n",
    "    all_refids = list(df_sliding_windows[\"refid\"])\n",
    "    all_NOR_nbrs = list(df_sliding_windows[\"NOR_nbr\"])\n",
    "    refid_NORs = []\n",
    "    for ref, nor in zip(all_refids, all_NOR_nbrs):\n",
    "        refid_NORs.append(str(ref)+\"-\"+str(nor))\n",
    "    \n",
    "    info_dict[\"refid_NOR\"].extend(refid_NORs)\n",
    "    info_dict[\"trans_id\"].extend(list(df_sliding_windows[\"trans_id\"]))\n",
    "    info_dict[\"refid\"].extend(all_refids)\n",
    "    info_dict[\"NOR_nbr\"].extend(all_NOR_nbrs)\n",
    "    info_dict[\"window_nbr\"].extend( list(df_sliding_windows[\"window_nbr\"]))\n",
    "    info_dict[\"nbr_CpGs\"].extend(list(df_sliding_windows[\"nbr_meth_CpGs\"])  )\n",
    "    info_dict[\"nuc_region_length\"].extend(list(df_sliding_windows[\"nuc_region_length\"]))\n",
    "    info_dict[\"nuc_rel_center\"].extend(list(df_sliding_windows[\"nuc_rel_center\"]))\n",
    "\n",
    "    all_scores =  list(df_sliding_windows[\"meth_rates_window\"]) #{34: 0.0, 35: 0.0,...}\n",
    "    c = 0\n",
    "    for row_df in tqdm(range(len(all_scores))):\n",
    "        c += 1\n",
    "        \n",
    "        # meth_rates_window = ast.literal_eval(all_scores[row_df])\n",
    "        meth_rates_window = all_scores[row_df]\n",
    "    \n",
    "        for param_str in params:\n",
    "            clash_thres = float(re.findall(r'\\d+', param_str)[0]) #c5m0\n",
    "            meth_thres = float(re.findall(r'\\d+', param_str)[1])\n",
    "            \n",
    "            perc_clash_ident = calc_perc_exp_clash_ident(x_y_clash_dict_norm, meth_rates_window, meth_thres, clash_thres)\n",
    "            info_dict[param_str].append(perc_clash_ident)\n",
    "            \n",
    "    #Built dataframe \n",
    "    df_scores = pd.DataFrame(0, index = np.arange(len(info_dict[column_names[0]])),columns = column_names)\n",
    "    for feat in column_names:\n",
    "        df_scores[feat] = info_dict[feat]\n",
    "\n",
    "    return df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# region = 'promoter'\n",
    "# region = 'intron.1.start'\n",
    "# region = 'intron.1.end'\n",
    "region = 'intron.2.start'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_path = main_path / 'Data' / 'sliding_window'\n",
    "df_NDR_sliding_windows = pd.read_csv(read_path / f'{region}.df_NDR_sliding_windows.csv')\n",
    "df_NDR_sliding_windows_random = pd.read_csv(read_path / f'{region}.df_NDR_sliding_windows_random.csv')\n",
    "df_NOR_sliding_windows = pd.read_csv(read_path / f'{region}.df_NOR_sliding_windows.csv')\n",
    "df_NOR_sliding_windows_random = pd.read_csv(read_path / f'{region}.df_NOR_sliding_windows_random.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NDR_sliding_windows['meth_rates_window'] = df_NDR_sliding_windows['meth_rates_window'].apply(ast.literal_eval)\n",
    "df_NDR_sliding_windows_random['meth_rates_window'] = df_NDR_sliding_windows_random['meth_rates_window'].apply(ast.literal_eval)\n",
    "df_NOR_sliding_windows['meth_rates_window'] = df_NOR_sliding_windows['meth_rates_window'].apply(ast.literal_eval)\n",
    "df_NOR_sliding_windows_random['meth_rates_window'] = df_NOR_sliding_windows_random['meth_rates_window'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NDR_sliding_windows.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NDR_score_exp = calc_score_lists(df_NDR_sliding_windows, x_y_clash_dict, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NDR_score_random = calc_score_lists(df_NDR_sliding_windows_random, x_y_clash_dict, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NDR_score_exp.shape, df_NDR_score_random.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NOR_score_exp = calc_score_lists(df_NOR_sliding_windows, x_y_clash_dict, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NOR_score_random = calc_score_lists(df_NOR_sliding_windows_random, x_y_clash_dict, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NOR_score_exp.shape, df_NOR_score_random.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NDR_score_exp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NDR_score_exp.to_csv(sliding_path / f'{region}.df_NDR_score_exp.csv', index=False)\n",
    "df_NDR_score_random.to_csv(sliding_path / f'{region}.df_NDR_score_random.csv', index=False)\n",
    "df_NOR_score_exp.to_csv(sliding_path / f'{region}.df_NOR_score_exp.csv', index=False)\n",
    "df_NOR_score_random.to_csv(sliding_path / f'{region}.df_NOR_score_random.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cohen's D and P values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from scipy import stats\n",
    "\n",
    "def calculate_cohens_d(list_EXP,list_RAND):\n",
    "    mEXP = np.mean(list_EXP)\n",
    "    sdEXP = np.std(list_EXP)\n",
    "    \n",
    "    mRAND = np.mean(list_RAND)\n",
    "    sdRAND = np.std(list_RAND)\n",
    "    \n",
    "    denom = np.sqrt(float(sdEXP**2 + sdRAND**2)/2.0)\n",
    "    cohens_d = float(mEXP-mRAND)/float(denom + 1e-6)\n",
    "    \n",
    "    return cohens_d\n",
    "\n",
    "def make_df_p_vals_cohens_d(df_scores_EXP, df_scores_RAND, params):\n",
    "    column_names = [\"nbr_CpGs\", \"parameter\", \"N_EXP\", \"N_RAND\", \"mean_EXP\", \"median_EXP\", \"std_EXP\", \"mean_RAND\",\n",
    "                    \"median_RAND\", \"std_RAND\", \"cohens_d\", \"is_normal_EXP\", \"is_normal_RAND\", \"pval_ttest\",\n",
    "                    \"t_stat\", \"pval_ranksums\", \"pval_ks_2samp\"]\n",
    "    info_dict = dict()\n",
    "    for col in column_names:\n",
    "        info_dict[col] = []\n",
    "\n",
    "    nbr_CpGs_list = list(set(list(df_scores_EXP[\"nbr_CpGs\"])))\n",
    "\n",
    "    for nbr_CpGs in nbr_CpGs_list:\n",
    "        df_scores_EXP_tmp = df_scores_EXP.loc[df_scores_EXP[\"nbr_CpGs\"] == nbr_CpGs]\n",
    "        df_scores_RAND_tmp = df_scores_RAND.loc[df_scores_RAND[\"nbr_CpGs\"] == nbr_CpGs]\n",
    "                    \n",
    "        for p in range(len(params)):\n",
    "            par_name = params[p]\n",
    "            EXP_scores = list(df_scores_EXP_tmp[par_name])\n",
    "            RAND_scores = list(df_scores_RAND_tmp[par_name])\n",
    "            \n",
    "            info_dict[\"nbr_CpGs\"].append(nbr_CpGs)\n",
    "            info_dict[\"parameter\"].append(par_name)\n",
    "            \n",
    "            info_dict[\"N_EXP\"].append(len(EXP_scores))\n",
    "            info_dict[\"N_RAND\"].append(len(RAND_scores))\n",
    "            \n",
    "            info_dict[\"mean_EXP\"].append(np.mean(EXP_scores))\n",
    "            info_dict[\"median_EXP\"].append(np.median(EXP_scores))\n",
    "            info_dict[\"std_EXP\"].append(np.std(EXP_scores))\n",
    "            \n",
    "            info_dict[\"mean_RAND\"].append(np.mean(RAND_scores))\n",
    "            info_dict[\"median_RAND\"].append(np.median(RAND_scores))\n",
    "            info_dict[\"std_RAND\"].append(np.std(RAND_scores))\n",
    "            \n",
    "            #EFFECT SIZE\n",
    "            cohens_d = calculate_cohens_d(EXP_scores, RAND_scores)\n",
    "            info_dict[\"cohens_d\"].append(cohens_d)\n",
    "            \n",
    "            #STAT TESTS\n",
    "            #is normal distributed? This function tests the null hypothesis that a sample comes from a normal distribution. If small -> ost likely not normal dustributed\n",
    "            pval_normal_EXP = stats.normaltest(EXP_scores)[1] if len(EXP_scores) >= 8 else -1\n",
    "            pval_normal_RAND = stats.normaltest(RAND_scores)[1] if len(EXP_scores) >= 8 else -1\n",
    "            \n",
    "            #students t\n",
    "            ttest_res = stats.ttest_ind(EXP_scores,RAND_scores,equal_var = False)\n",
    "            t_stat = ttest_res[0]\n",
    "            p_val_ttest = float(ttest_res[1])/2.0\n",
    "            \n",
    "            #ranksums, kstest\n",
    "            ranksums = scipy.stats.ranksums(EXP_scores,RAND_scores)[1]\n",
    "            ks_2samp = scipy.stats.ks_2samp(EXP_scores,RAND_scores)[1]\n",
    "    \n",
    "            info_dict[\"is_normal_EXP\"].append(pval_normal_EXP)\n",
    "            info_dict[\"is_normal_RAND\"].append(pval_normal_RAND)\n",
    "            info_dict[\"pval_ttest\"].append(p_val_ttest)\n",
    "            info_dict[\"t_stat\"].append(t_stat)\n",
    "            info_dict[\"pval_ranksums\"].append(ranksums)\n",
    "            info_dict[\"pval_ks_2samp\"].append(ks_2samp)\n",
    "            \n",
    "    #Built dataframe\n",
    "    df = pd.DataFrame(0, index = np.arange(len(info_dict[\"nbr_CpGs\"])),columns = column_names)\n",
    "    for feat in column_names:\n",
    "        df[feat] = info_dict[feat]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# region = 'promoter'\n",
    "# region = 'intron.1.start'\n",
    "# region = 'intron.1.end'\n",
    "region = 'intron.2.start'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NDR_score_exp = pd.read_csv(sliding_path / f'{region}.df_NDR_score_exp.csv')\n",
    "df_NDR_score_random = pd.read_csv(sliding_path / f'{region}.df_NDR_score_random.csv')\n",
    "df_NOR_score_exp = pd.read_csv(sliding_path / f'{region}.df_NOR_score_exp.csv')\n",
    "df_NOR_score_random = pd.read_csv(sliding_path / f'{region}.df_NOR_score_random.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NDR_pvalues = make_df_p_vals_cohens_d(df_NDR_score_exp, df_NDR_score_random, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NOR_pvalues = make_df_p_vals_cohens_d(df_NOR_score_exp, df_NOR_score_random, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NDR_pvalues.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "groups = df_NDR_pvalues.groupby(by='parameter')\n",
    "for par, df_tmp in groups:\n",
    "    plt.scatter(df_tmp['nbr_CpGs'], df_tmp['N_EXP'], label=par)\n",
    "\n",
    "# plt.axhline(y=50)\n",
    "plt.xlim(-2,30)\n",
    "# plt.ylim((10**1,10**6))\n",
    "# plt.legend()\n",
    "plt.xlabel('Number of CpGs in sliding window', fontsize=22)\n",
    "plt.ylabel('Sample size for Cohen’s D', fontsize=22)\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "groups = df_NOR_pvalues.groupby(by='parameter')\n",
    "for par, df_tmp in groups:\n",
    "    plt.scatter(df_tmp['nbr_CpGs'], df_tmp['N_EXP'], label=par)\n",
    "plt.xlim(-2,30)\n",
    "# plt.legend()\n",
    "plt.xlabel('Number of CpGs in sliding window', fontsize=22)\n",
    "plt.ylabel('Sample size for Cohen’s D', fontsize=22)\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_nbr_CpGs_cohensd(df_values, params):\n",
    "    plt.figure(figsize=(15,7))\n",
    "    ax = plt.subplot(1,1,1)\n",
    "    \n",
    "    nbr_CpGs_list = sorted(list(set(list(df_values[\"nbr_CpGs\"]))))\n",
    "\n",
    "    for par_name in params:\n",
    "        \n",
    "        df_values_tmp = df_values.loc[df_values[\"parameter\"] == par_name]\n",
    "        \n",
    "        x_nbr_cpg_vals = list(df_values_tmp[\"nbr_CpGs\"])\n",
    "        y_cohens_d_vals = list(df_values_tmp[\"cohens_d\"])\n",
    "        \n",
    "        if \"m0\" in par_name:\n",
    "            c = \"#117A65\"\n",
    "        if \"m10\" in par_name:\n",
    "            c = \"#45B39D\"\n",
    "        if \"m20\" in par_name:\n",
    "            c = \"#EB984E\"\n",
    "        if \"c5\" in par_name:\n",
    "            m = \"*\"\n",
    "            ms = 15\n",
    "        if \"c10\" in par_name:\n",
    "            m = \"^\"\n",
    "            ms = 10\n",
    "        if \"c20\" in par_name:\n",
    "            m = \"s\"\n",
    "            ms = 10\n",
    "        if \"c50\" in par_name:\n",
    "            m = \"o\"\n",
    "            ms = 10\n",
    "        \n",
    "        \n",
    "        plt.plot(x_nbr_cpg_vals, y_cohens_d_vals, linestyle=\"-\", color=c, marker=m, markersize=ms, label=par_name)\n",
    "    \n",
    "    \n",
    "    plt.axhline(y=0.2, linewidth=1, color = '#2C3E50',linestyle='--')\n",
    "    plt.axhline(y=0.5, linewidth=1, color = '#2C3E50',linestyle='--')\n",
    "    plt.axhline(y=0.8, linewidth=1, color = '#2C3E50',linestyle='--')\n",
    "    \n",
    "    e = 0.02\n",
    "    ax.text(-1.8,0.2+e, \"Small ES\")\n",
    "    ax.text(-1.8,0.5+e, \"Medium ES\")\n",
    "    ax.text(-1.8,0.8+e, \"Large ES\")\n",
    "\n",
    "    ax.set_ylabel(\"Cohen's D\", fontsize=22)\n",
    "    ax.set_xlabel(\"Number of CpGs in sliding window\", fontsize=22)   \n",
    "\n",
    "    plt.xlim(-2,30)\n",
    "    plt.ylim(-5,5)\n",
    "    plt.xticks(fontsize=18)\n",
    "    plt.yticks(fontsize=18)\n",
    "\n",
    "    legend = ax.legend(loc=\"lower left\", ncol=4, frameon = 1, prop={'size':18})\n",
    "    legend.get_frame().set_facecolor('white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_nbr_CpGs_cohensd(df_NDR_pvalues, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_nbr_CpGs_cohensd(df_NOR_pvalues, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pvals_cohensd(df_values,params):\n",
    "    \n",
    "    plt.figure(figsize=(15,7))\n",
    "    ax = plt.subplot(1,1,1)\n",
    "    \n",
    "    nbr_CpGs_list = sorted(list(set(list(df_values[\"nbr_CpGs\"]))))\n",
    "    \n",
    "    for par_name in params:\n",
    "        df_values_tmp = df_values.loc[df_values[\"parameter\"] == par_name]\n",
    "        \n",
    "        x_nbr_cpg_vals = list(df_values_tmp[\"nbr_CpGs\"])\n",
    "        y_pvals_vals = list(df_values_tmp[\"pval_ranksums\"])\n",
    "        \n",
    "        y_pvals_log = [-np.log10(p_val) if p_val != 0.0 else 310 for p_val in y_pvals_vals]\n",
    "        # print(min([p_val for p_val in y_pvals_vals]))\n",
    "        # y_pvals_log = [-np.log10(p_val) for p_val in y_pvals_vals]\n",
    "        \n",
    "        if \"m0\" in par_name:\n",
    "            c = \"#117A65\"\n",
    "        if \"m10\" in par_name:\n",
    "            c = \"#45B39D\"\n",
    "        if \"m20\" in par_name:\n",
    "            c = \"#EB984E\"\n",
    "        if \"c5\" in par_name:\n",
    "            m = \"*\"\n",
    "            ms = 15\n",
    "        if \"c10\" in par_name:\n",
    "            m = \"^\"\n",
    "            ms = 10\n",
    "        if \"c20\" in par_name:\n",
    "            m = \"s\"\n",
    "            ms = 10\n",
    "        if \"c50\" in par_name:\n",
    "            m = \"o\"\n",
    "            ms = 10\n",
    "        \n",
    "        \n",
    "        plt.plot(x_nbr_cpg_vals,y_pvals_log,linestyle=\"-\",color=c,marker=m,markersize=ms,label=par_name)\n",
    "    \n",
    "    \n",
    "    #plt.axhline(y=-np.log10(0.05), linewidth=1, color = '#5D6D7E',linestyle='-')\n",
    "    #plt.axhline(y=-np.log10(0.01), linewidth=1, color = '#515A5A',linestyle='-')\n",
    "\n",
    "    ax.set_ylabel(\"-log10(P-value)\", fontsize=22)\n",
    "    ax.set_xlabel(\"Number of CpGs in sliding window\", fontsize=22)   \n",
    "\n",
    "    plt.xlim(-2, 30)\n",
    "    plt.ylim(0, 450)\n",
    "    plt.xticks(fontsize=18)\n",
    "    plt.yticks(fontsize=18)\n",
    "\n",
    "    legend = ax.legend(loc=\"upper right\",ncol=4,frameon = 1,prop={'size':18})\n",
    "    legend.get_frame().set_facecolor('white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pvals_cohensd(df_NDR_pvalues, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pvals_cohensd(df_NOR_pvalues, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cohen's D Calculation Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from scipy import stats\n",
    "\n",
    "def calculate_cohens_d(list_EXP,list_RAND):\n",
    "    mEXP = np.mean(list_EXP)\n",
    "    sdEXP = np.std(list_EXP)\n",
    "    \n",
    "    mRAND = np.mean(list_RAND)\n",
    "    sdRAND = np.std(list_RAND)\n",
    "    \n",
    "    denom = np.sqrt(float(sdEXP**2 + sdRAND**2)/2.0)\n",
    "    cohens_d = float(mEXP-mRAND)/float(denom + 1e-6)\n",
    "    \n",
    "    return cohens_d\n",
    "\n",
    "def make_df_cohens_d(df_scores_EXP, df_scores_RAND, params):\n",
    "    column_names = [\"parameter\", \"N_EXP\", \"N_RAND\", \"mean_EXP\", \"median_EXP\", \"std_EXP\", \"mean_RAND\",\n",
    "                    \"median_RAND\", \"std_RAND\", \"cohens_d\", \"is_normal_EXP\", \"is_normal_RAND\", \"pval_ttest\",\n",
    "                    \"t_stat\", \"pval_ranksums\", \"pval_ks_2samp\"]\n",
    "    info_dict = dict()\n",
    "    for col in column_names:\n",
    "        info_dict[col] = []\n",
    "    \n",
    "    df_scores_EXP_tmp = df_scores_EXP.loc[df_scores_EXP['nbr_CpGs'].between(10,20)]\n",
    "    df_scores_RAND_tmp = df_scores_RAND.loc[df_scores_RAND['nbr_CpGs'].between(10,20)]\n",
    "                    \n",
    "    for p in range(len(params)):\n",
    "        par_name = params[p]\n",
    "        EXP_scores = list(df_scores_EXP_tmp[par_name])\n",
    "        RAND_scores = list(df_scores_RAND_tmp[par_name])\n",
    "        \n",
    "        # info_dict[\"nbr_CpGs\"].append(nbr_CpGs)\n",
    "        info_dict[\"parameter\"].append(par_name)\n",
    "        \n",
    "        info_dict[\"N_EXP\"].append(len(EXP_scores))\n",
    "        info_dict[\"N_RAND\"].append(len(RAND_scores))\n",
    "        \n",
    "        info_dict[\"mean_EXP\"].append(np.mean(EXP_scores))\n",
    "        info_dict[\"median_EXP\"].append(np.median(EXP_scores))\n",
    "        info_dict[\"std_EXP\"].append(np.std(EXP_scores))\n",
    "        \n",
    "        info_dict[\"mean_RAND\"].append(np.mean(RAND_scores))\n",
    "        info_dict[\"median_RAND\"].append(np.median(RAND_scores))\n",
    "        info_dict[\"std_RAND\"].append(np.std(RAND_scores))\n",
    "        \n",
    "        #EFFECT SIZE\n",
    "        cohens_d = calculate_cohens_d(EXP_scores, RAND_scores)\n",
    "        info_dict[\"cohens_d\"].append(cohens_d)\n",
    "        \n",
    "        #STAT TESTS\n",
    "        #is normal distributed? This function tests the null hypothesis that a sample comes from a normal distribution. If small -> ost likely not normal dustributed\n",
    "        pval_normal_EXP = stats.normaltest(EXP_scores)[1] if len(EXP_scores) >= 8 else -1\n",
    "        pval_normal_RAND = stats.normaltest(RAND_scores)[1] if len(EXP_scores) >= 8 else -1\n",
    "        \n",
    "        #students t\n",
    "        ttest_res = stats.ttest_ind(EXP_scores,RAND_scores,equal_var = False)\n",
    "        t_stat = ttest_res[0]\n",
    "        p_val_ttest = float(ttest_res[1])/2.0\n",
    "        \n",
    "        #ranksums, kstest\n",
    "        ranksums = scipy.stats.ranksums(EXP_scores,RAND_scores)[1]\n",
    "        ks_2samp = scipy.stats.ks_2samp(EXP_scores,RAND_scores)[1]\n",
    "\n",
    "        info_dict[\"is_normal_EXP\"].append(pval_normal_EXP)\n",
    "        info_dict[\"is_normal_RAND\"].append(pval_normal_RAND)\n",
    "        info_dict[\"pval_ttest\"].append(p_val_ttest)\n",
    "        info_dict[\"t_stat\"].append(t_stat)\n",
    "        info_dict[\"pval_ranksums\"].append(ranksums)\n",
    "        info_dict[\"pval_ks_2samp\"].append(ks_2samp)\n",
    "            \n",
    "    #Built dataframe\n",
    "    df = pd.DataFrame(0, index = np.arange(len(info_dict[\"parameter\"])),columns = column_names)\n",
    "    for feat in column_names:\n",
    "        df[feat] = info_dict[feat]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# region = 'promoter'\n",
    "# region = 'intron.1.start'\n",
    "# region = 'intron.1.end'\n",
    "# region = 'intron.2.start'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_NDR_score_exp = pd.read_csv(sliding_path / f'{region}.df_NDR_score_exp.csv')\n",
    "# df_NDR_score_random = pd.read_csv(sliding_path / f'{region}.df_NDR_score_random.csv')\n",
    "# df_NOR_score_exp = pd.read_csv(sliding_path / f'{region}.df_NOR_score_exp.csv')\n",
    "# df_NOR_score_random = pd.read_csv(sliding_path / f'{region}.df_NOR_score_random.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_NDR_pvalues = make_df_cohens_d(df_NDR_score_exp, df_NDR_score_random, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_NOR_pvalues = make_df_cohens_d(df_NOR_score_exp, df_NOR_score_random, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_NDR_pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_NOR_pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "promoter\n",
      "intron.1.start\n",
      "intron.1.end\n",
      "intron.2.start\n"
     ]
    }
   ],
   "source": [
    "regions = ['promoter', 'intron.1.start', 'intron.1.end', 'intron.2.start']\n",
    "labels = ['promoter', 'start of 1st intron', 'end of 1st intron', 'start of 2nd intron']\n",
    "table = {}\n",
    "for label, region in zip(labels, regions):\n",
    "    print(region)\n",
    "    df_NDR_score_exp = pd.read_csv(sliding_path / f'{region}.df_NDR_score_exp.csv')\n",
    "    df_NDR_score_random = pd.read_csv(sliding_path / f'{region}.df_NDR_score_random.csv')\n",
    "    df_NOR_score_exp = pd.read_csv(sliding_path / f'{region}.df_NOR_score_exp.csv')\n",
    "    df_NOR_score_random = pd.read_csv(sliding_path / f'{region}.df_NOR_score_random.csv')\n",
    "\n",
    "    df_NDR_pvalues = make_df_cohens_d(df_NDR_score_exp, df_NDR_score_random, params)\n",
    "    df_NOR_pvalues = make_df_cohens_d(df_NOR_score_exp, df_NOR_score_random, params)\n",
    "\n",
    "    assert df_NDR_pvalues.shape[0] == df_NOR_pvalues.shape[0]\n",
    "    assert df_NDR_pvalues['parameter'].to_list() == df_NOR_pvalues['parameter'].to_list()\n",
    "\n",
    "    table[label] = {\n",
    "        'Parameter': df_NDR_pvalues['parameter'].to_list(),\n",
    "        'HNDRs': df_NOR_pvalues['cohens_d'].to_list(),\n",
    "        'LNDRs': df_NDR_pvalues['cohens_d'].to_list()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_table = pd.DataFrame(table).T.explode(['Parameter', 'LNDRs', 'HNDRs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameter</th>\n",
       "      <th>HNDRs</th>\n",
       "      <th>LNDRs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>promoter</th>\n",
       "      <td>c5m0</td>\n",
       "      <td>1.33019</td>\n",
       "      <td>0.624352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>promoter</th>\n",
       "      <td>c5m10</td>\n",
       "      <td>1.331086</td>\n",
       "      <td>0.623447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>promoter</th>\n",
       "      <td>c5m20</td>\n",
       "      <td>1.36375</td>\n",
       "      <td>0.705061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>promoter</th>\n",
       "      <td>c10m0</td>\n",
       "      <td>1.059914</td>\n",
       "      <td>0.497207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>promoter</th>\n",
       "      <td>c10m10</td>\n",
       "      <td>1.060267</td>\n",
       "      <td>0.496213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>promoter</th>\n",
       "      <td>c10m20</td>\n",
       "      <td>1.075488</td>\n",
       "      <td>0.559903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>promoter</th>\n",
       "      <td>c20m0</td>\n",
       "      <td>0.505064</td>\n",
       "      <td>0.233044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>promoter</th>\n",
       "      <td>c20m10</td>\n",
       "      <td>0.505116</td>\n",
       "      <td>0.231603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>promoter</th>\n",
       "      <td>c20m20</td>\n",
       "      <td>0.508779</td>\n",
       "      <td>0.259142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>promoter</th>\n",
       "      <td>c50m0</td>\n",
       "      <td>-0.478801</td>\n",
       "      <td>-0.241071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>promoter</th>\n",
       "      <td>c50m10</td>\n",
       "      <td>-0.478907</td>\n",
       "      <td>-0.241644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>promoter</th>\n",
       "      <td>c50m20</td>\n",
       "      <td>-0.487291</td>\n",
       "      <td>-0.274771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start of 1st intron</th>\n",
       "      <td>c5m0</td>\n",
       "      <td>1.820201</td>\n",
       "      <td>0.999308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start of 1st intron</th>\n",
       "      <td>c5m10</td>\n",
       "      <td>1.818644</td>\n",
       "      <td>1.000642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start of 1st intron</th>\n",
       "      <td>c5m20</td>\n",
       "      <td>1.887055</td>\n",
       "      <td>1.080971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start of 1st intron</th>\n",
       "      <td>c10m0</td>\n",
       "      <td>1.462883</td>\n",
       "      <td>0.805074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start of 1st intron</th>\n",
       "      <td>c10m10</td>\n",
       "      <td>1.461406</td>\n",
       "      <td>0.806092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start of 1st intron</th>\n",
       "      <td>c10m20</td>\n",
       "      <td>1.515659</td>\n",
       "      <td>0.873474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start of 1st intron</th>\n",
       "      <td>c20m0</td>\n",
       "      <td>0.714291</td>\n",
       "      <td>0.380901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start of 1st intron</th>\n",
       "      <td>c20m10</td>\n",
       "      <td>0.713739</td>\n",
       "      <td>0.381012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start of 1st intron</th>\n",
       "      <td>c20m20</td>\n",
       "      <td>0.740624</td>\n",
       "      <td>0.415476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start of 1st intron</th>\n",
       "      <td>c50m0</td>\n",
       "      <td>-0.700564</td>\n",
       "      <td>-0.41714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start of 1st intron</th>\n",
       "      <td>c50m10</td>\n",
       "      <td>-0.699122</td>\n",
       "      <td>-0.417998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start of 1st intron</th>\n",
       "      <td>c50m20</td>\n",
       "      <td>-0.727421</td>\n",
       "      <td>-0.449691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>end of 1st intron</th>\n",
       "      <td>c5m0</td>\n",
       "      <td>1.879247</td>\n",
       "      <td>1.464549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>end of 1st intron</th>\n",
       "      <td>c5m10</td>\n",
       "      <td>1.870091</td>\n",
       "      <td>1.462206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>end of 1st intron</th>\n",
       "      <td>c5m20</td>\n",
       "      <td>1.881168</td>\n",
       "      <td>1.491997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>end of 1st intron</th>\n",
       "      <td>c10m0</td>\n",
       "      <td>1.566767</td>\n",
       "      <td>1.20746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>end of 1st intron</th>\n",
       "      <td>c10m10</td>\n",
       "      <td>1.56039</td>\n",
       "      <td>1.205976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>end of 1st intron</th>\n",
       "      <td>c10m20</td>\n",
       "      <td>1.576244</td>\n",
       "      <td>1.23744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>end of 1st intron</th>\n",
       "      <td>c20m0</td>\n",
       "      <td>0.806439</td>\n",
       "      <td>0.610543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>end of 1st intron</th>\n",
       "      <td>c20m10</td>\n",
       "      <td>0.803917</td>\n",
       "      <td>0.610286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>end of 1st intron</th>\n",
       "      <td>c20m20</td>\n",
       "      <td>0.821395</td>\n",
       "      <td>0.627849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>end of 1st intron</th>\n",
       "      <td>c50m0</td>\n",
       "      <td>-0.776082</td>\n",
       "      <td>-0.563165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>end of 1st intron</th>\n",
       "      <td>c50m10</td>\n",
       "      <td>-0.772958</td>\n",
       "      <td>-0.563333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>end of 1st intron</th>\n",
       "      <td>c50m20</td>\n",
       "      <td>-0.801982</td>\n",
       "      <td>-0.588636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start of 2nd intron</th>\n",
       "      <td>c5m0</td>\n",
       "      <td>2.166621</td>\n",
       "      <td>1.433047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start of 2nd intron</th>\n",
       "      <td>c5m10</td>\n",
       "      <td>2.16484</td>\n",
       "      <td>1.43291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start of 2nd intron</th>\n",
       "      <td>c5m20</td>\n",
       "      <td>2.216755</td>\n",
       "      <td>1.48451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start of 2nd intron</th>\n",
       "      <td>c10m0</td>\n",
       "      <td>1.73449</td>\n",
       "      <td>1.17683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start of 2nd intron</th>\n",
       "      <td>c10m10</td>\n",
       "      <td>1.732603</td>\n",
       "      <td>1.17686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start of 2nd intron</th>\n",
       "      <td>c10m20</td>\n",
       "      <td>1.770239</td>\n",
       "      <td>1.224338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start of 2nd intron</th>\n",
       "      <td>c20m0</td>\n",
       "      <td>0.848057</td>\n",
       "      <td>0.589935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start of 2nd intron</th>\n",
       "      <td>c20m10</td>\n",
       "      <td>0.847064</td>\n",
       "      <td>0.590024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start of 2nd intron</th>\n",
       "      <td>c20m20</td>\n",
       "      <td>0.859927</td>\n",
       "      <td>0.613421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start of 2nd intron</th>\n",
       "      <td>c50m0</td>\n",
       "      <td>-0.798815</td>\n",
       "      <td>-0.56379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start of 2nd intron</th>\n",
       "      <td>c50m10</td>\n",
       "      <td>-0.797611</td>\n",
       "      <td>-0.56391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start of 2nd intron</th>\n",
       "      <td>c50m20</td>\n",
       "      <td>-0.834395</td>\n",
       "      <td>-0.595169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Parameter     HNDRs     LNDRs\n",
       "promoter                 c5m0   1.33019  0.624352\n",
       "promoter                c5m10  1.331086  0.623447\n",
       "promoter                c5m20   1.36375  0.705061\n",
       "promoter                c10m0  1.059914  0.497207\n",
       "promoter               c10m10  1.060267  0.496213\n",
       "promoter               c10m20  1.075488  0.559903\n",
       "promoter                c20m0  0.505064  0.233044\n",
       "promoter               c20m10  0.505116  0.231603\n",
       "promoter               c20m20  0.508779  0.259142\n",
       "promoter                c50m0 -0.478801 -0.241071\n",
       "promoter               c50m10 -0.478907 -0.241644\n",
       "promoter               c50m20 -0.487291 -0.274771\n",
       "start of 1st intron      c5m0  1.820201  0.999308\n",
       "start of 1st intron     c5m10  1.818644  1.000642\n",
       "start of 1st intron     c5m20  1.887055  1.080971\n",
       "start of 1st intron     c10m0  1.462883  0.805074\n",
       "start of 1st intron    c10m10  1.461406  0.806092\n",
       "start of 1st intron    c10m20  1.515659  0.873474\n",
       "start of 1st intron     c20m0  0.714291  0.380901\n",
       "start of 1st intron    c20m10  0.713739  0.381012\n",
       "start of 1st intron    c20m20  0.740624  0.415476\n",
       "start of 1st intron     c50m0 -0.700564  -0.41714\n",
       "start of 1st intron    c50m10 -0.699122 -0.417998\n",
       "start of 1st intron    c50m20 -0.727421 -0.449691\n",
       "end of 1st intron        c5m0  1.879247  1.464549\n",
       "end of 1st intron       c5m10  1.870091  1.462206\n",
       "end of 1st intron       c5m20  1.881168  1.491997\n",
       "end of 1st intron       c10m0  1.566767   1.20746\n",
       "end of 1st intron      c10m10   1.56039  1.205976\n",
       "end of 1st intron      c10m20  1.576244   1.23744\n",
       "end of 1st intron       c20m0  0.806439  0.610543\n",
       "end of 1st intron      c20m10  0.803917  0.610286\n",
       "end of 1st intron      c20m20  0.821395  0.627849\n",
       "end of 1st intron       c50m0 -0.776082 -0.563165\n",
       "end of 1st intron      c50m10 -0.772958 -0.563333\n",
       "end of 1st intron      c50m20 -0.801982 -0.588636\n",
       "start of 2nd intron      c5m0  2.166621  1.433047\n",
       "start of 2nd intron     c5m10   2.16484   1.43291\n",
       "start of 2nd intron     c5m20  2.216755   1.48451\n",
       "start of 2nd intron     c10m0   1.73449   1.17683\n",
       "start of 2nd intron    c10m10  1.732603   1.17686\n",
       "start of 2nd intron    c10m20  1.770239  1.224338\n",
       "start of 2nd intron     c20m0  0.848057  0.589935\n",
       "start of 2nd intron    c20m10  0.847064  0.590024\n",
       "start of 2nd intron    c20m20  0.859927  0.613421\n",
       "start of 2nd intron     c50m0 -0.798815  -0.56379\n",
       "start of 2nd intron    c50m10 -0.797611  -0.56391\n",
       "start of 2nd intron    c50m20 -0.834395 -0.595169"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llll}\n",
      "\\toprule\n",
      "{} & Parameter & HNDRs & LNDRs \\\\\n",
      "\\midrule\n",
      "promoter            &      c5m0 &  1.33 &  0.62 \\\\\n",
      "promoter            &     c5m10 &  1.33 &  0.62 \\\\\n",
      "promoter            &     c5m20 &  1.36 &  0.71 \\\\\n",
      "promoter            &     c10m0 &  1.06 &  0.50 \\\\\n",
      "promoter            &    c10m10 &  1.06 &  0.50 \\\\\n",
      "promoter            &    c10m20 &  1.08 &  0.56 \\\\\n",
      "promoter            &     c20m0 &  0.51 &  0.23 \\\\\n",
      "promoter            &    c20m10 &  0.51 &  0.23 \\\\\n",
      "promoter            &    c20m20 &  0.51 &  0.26 \\\\\n",
      "promoter            &     c50m0 & -0.48 & -0.24 \\\\\n",
      "promoter            &    c50m10 & -0.48 & -0.24 \\\\\n",
      "promoter            &    c50m20 & -0.49 & -0.27 \\\\\n",
      "start of 1st intron &      c5m0 &  1.82 &  1.00 \\\\\n",
      "start of 1st intron &     c5m10 &  1.82 &  1.00 \\\\\n",
      "start of 1st intron &     c5m20 &  1.89 &  1.08 \\\\\n",
      "start of 1st intron &     c10m0 &  1.46 &  0.81 \\\\\n",
      "start of 1st intron &    c10m10 &  1.46 &  0.81 \\\\\n",
      "start of 1st intron &    c10m20 &  1.52 &  0.87 \\\\\n",
      "start of 1st intron &     c20m0 &  0.71 &  0.38 \\\\\n",
      "start of 1st intron &    c20m10 &  0.71 &  0.38 \\\\\n",
      "start of 1st intron &    c20m20 &  0.74 &  0.42 \\\\\n",
      "start of 1st intron &     c50m0 & -0.70 & -0.42 \\\\\n",
      "start of 1st intron &    c50m10 & -0.70 & -0.42 \\\\\n",
      "start of 1st intron &    c50m20 & -0.73 & -0.45 \\\\\n",
      "end of 1st intron   &      c5m0 &  1.88 &  1.46 \\\\\n",
      "end of 1st intron   &     c5m10 &  1.87 &  1.46 \\\\\n",
      "end of 1st intron   &     c5m20 &  1.88 &  1.49 \\\\\n",
      "end of 1st intron   &     c10m0 &  1.57 &  1.21 \\\\\n",
      "end of 1st intron   &    c10m10 &  1.56 &  1.21 \\\\\n",
      "end of 1st intron   &    c10m20 &  1.58 &  1.24 \\\\\n",
      "end of 1st intron   &     c20m0 &  0.81 &  0.61 \\\\\n",
      "end of 1st intron   &    c20m10 &  0.80 &  0.61 \\\\\n",
      "end of 1st intron   &    c20m20 &  0.82 &  0.63 \\\\\n",
      "end of 1st intron   &     c50m0 & -0.78 & -0.56 \\\\\n",
      "end of 1st intron   &    c50m10 & -0.77 & -0.56 \\\\\n",
      "end of 1st intron   &    c50m20 & -0.80 & -0.59 \\\\\n",
      "start of 2nd intron &      c5m0 &  2.17 &  1.43 \\\\\n",
      "start of 2nd intron &     c5m10 &  2.16 &  1.43 \\\\\n",
      "start of 2nd intron &     c5m20 &  2.22 &  1.48 \\\\\n",
      "start of 2nd intron &     c10m0 &  1.73 &  1.18 \\\\\n",
      "start of 2nd intron &    c10m10 &  1.73 &  1.18 \\\\\n",
      "start of 2nd intron &    c10m20 &  1.77 &  1.22 \\\\\n",
      "start of 2nd intron &     c20m0 &  0.85 &  0.59 \\\\\n",
      "start of 2nd intron &    c20m10 &  0.85 &  0.59 \\\\\n",
      "start of 2nd intron &    c20m20 &  0.86 &  0.61 \\\\\n",
      "start of 2nd intron &     c50m0 & -0.80 & -0.56 \\\\\n",
      "start of 2nd intron &    c50m10 & -0.80 & -0.56 \\\\\n",
      "start of 2nd intron &    c50m20 & -0.83 & -0.60 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3784335/2883573959.py:1: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(df_table.to_latex(float_format=\"{:.2f}\".format))\n"
     ]
    }
   ],
   "source": [
    "print(df_table.to_latex(float_format=\"{:.2f}\".format))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameter</th>\n",
       "      <th>HNDRs</th>\n",
       "      <th>LNDRs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>promoter</th>\n",
       "      <td>c5m0</td>\n",
       "      <td>1.33019</td>\n",
       "      <td>0.624352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>promoter</th>\n",
       "      <td>c5m10</td>\n",
       "      <td>1.331086</td>\n",
       "      <td>0.623447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>promoter</th>\n",
       "      <td>c5m20</td>\n",
       "      <td>1.36375</td>\n",
       "      <td>0.705061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start of 1st intron</th>\n",
       "      <td>c5m0</td>\n",
       "      <td>1.820201</td>\n",
       "      <td>0.999308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start of 1st intron</th>\n",
       "      <td>c5m10</td>\n",
       "      <td>1.818644</td>\n",
       "      <td>1.000642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start of 1st intron</th>\n",
       "      <td>c5m20</td>\n",
       "      <td>1.887055</td>\n",
       "      <td>1.080971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>end of 1st intron</th>\n",
       "      <td>c5m0</td>\n",
       "      <td>1.879247</td>\n",
       "      <td>1.464549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>end of 1st intron</th>\n",
       "      <td>c5m10</td>\n",
       "      <td>1.870091</td>\n",
       "      <td>1.462206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>end of 1st intron</th>\n",
       "      <td>c5m20</td>\n",
       "      <td>1.881168</td>\n",
       "      <td>1.491997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start of 2nd intron</th>\n",
       "      <td>c5m0</td>\n",
       "      <td>2.166621</td>\n",
       "      <td>1.433047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start of 2nd intron</th>\n",
       "      <td>c5m10</td>\n",
       "      <td>2.16484</td>\n",
       "      <td>1.43291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start of 2nd intron</th>\n",
       "      <td>c5m20</td>\n",
       "      <td>2.216755</td>\n",
       "      <td>1.48451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Parameter     HNDRs     LNDRs\n",
       "promoter                 c5m0   1.33019  0.624352\n",
       "promoter                c5m10  1.331086  0.623447\n",
       "promoter                c5m20   1.36375  0.705061\n",
       "start of 1st intron      c5m0  1.820201  0.999308\n",
       "start of 1st intron     c5m10  1.818644  1.000642\n",
       "start of 1st intron     c5m20  1.887055  1.080971\n",
       "end of 1st intron        c5m0  1.879247  1.464549\n",
       "end of 1st intron       c5m10  1.870091  1.462206\n",
       "end of 1st intron       c5m20  1.881168  1.491997\n",
       "start of 2nd intron      c5m0  2.166621  1.433047\n",
       "start of 2nd intron     c5m10   2.16484   1.43291\n",
       "start of 2nd intron     c5m20  2.216755   1.48451"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_table[df_table['Parameter'].isin(['c5m0', 'c5m10', 'c5m20'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = 'promoter'\n",
    "# region = 'intron.1.start'\n",
    "# region = 'intron.1.end'\n",
    "# region = 'intron.2.start'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NDR_score_exp = pd.read_csv(sliding_path / f'{region}.df_NDR_score_exp.csv')\n",
    "df_NDR_score_random = pd.read_csv(sliding_path / f'{region}.df_NDR_score_random.csv')\n",
    "df_NOR_score_exp = pd.read_csv(sliding_path / f'{region}.df_NOR_score_exp.csv')\n",
    "df_NOR_score_random = pd.read_csv(sliding_path / f'{region}.df_NOR_score_random.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NDR_score_exp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 4, figsize=(20,12), layout='constrained')\n",
    "order = ['c5m0', 'c10m0', 'c20m0', 'c50m0', 'c5m10', 'c10m10', 'c20m10', 'c50m10', 'c5m20', 'c10m20', 'c20m20', 'c50m20']\n",
    "\n",
    "for ax, thresh in zip(axs.flatten(), order):\n",
    "    ax.hist(df_NDR_score_random.loc[df_NDR_score_random['nbr_CpGs'].between(10,20), thresh], density=True, alpha=0.5, bins=np.linspace(0,1,20), label='random')\n",
    "    ax.hist(df_NDR_score_exp.loc[df_NDR_score_exp['nbr_CpGs'].between(10,20), thresh], density=True, alpha=0.3, bins=np.linspace(0,1,20), label='experimental')\n",
    "    ax.set_title(thresh, fontsize=20)\n",
    "    ax.set_xlabel('match-score', fontsize=16)\n",
    "    ax.set_ylabel('density', fontsize=16)\n",
    "    ax.legend(fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 4, figsize=(20,12), layout='constrained')\n",
    "order = ['c5m0', 'c10m0', 'c20m0', 'c50m0', 'c5m10', 'c10m10', 'c20m10', 'c50m10', 'c5m20', 'c10m20', 'c20m20', 'c50m20']\n",
    "\n",
    "for ax, thresh in zip(axs.flatten(), order):\n",
    "    ax.hist(df_NOR_score_random.loc[df_NOR_score_random['nbr_CpGs'].between(10,20), thresh], density=True, alpha=0.5, bins=np.linspace(0,1,20), label='random')\n",
    "    ax.hist(df_NOR_score_exp.loc[df_NOR_score_exp['nbr_CpGs'].between(10,20), thresh], density=True, alpha=0.3, bins=np.linspace(0,1,20), label='experimental')\n",
    "    ax.set_title(thresh, fontsize=20)\n",
    "    ax.set_xlabel('match-score', fontsize=16)\n",
    "    ax.set_ylabel('density', fontsize=16)\n",
    "    ax.legend(fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "helms-lab-jupyter",
   "language": "python",
   "name": "helms-lab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
