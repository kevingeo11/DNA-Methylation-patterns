{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from workspace import nometools as nome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import pickle\n",
    "import scipy\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_path = '/home/kevin/DNA-Methylation-patterns/'\n",
    "data_path = main_path + 'delete/'\n",
    "tmp_path = data_path + 'prommoter/'\n",
    "steric_path = main_path + 'delete/steric_clash/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = 'promoter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "import multiprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def getGCHcount_in_window(window, res, pos):\n",
    "#     '''\n",
    "#         element in res = ['chr20', 60110, 60111, '+', 0.0, 3]\n",
    "#     '''\n",
    "#     start, end = window\n",
    "#     freq = []\n",
    "#     meth_c_count = 0\n",
    "#     net_c_count = 0\n",
    "#     for itr in range(pos, len(res)):\n",
    "#         if start > res[itr][1]:\n",
    "#             ## increase the start of the search such that we start near the window\n",
    "#             pos += 1\n",
    "#         elif start <= res[itr][1] and end >= res[itr][1]:\n",
    "#             freq.append((res[itr][1], res[itr][4], res[itr][5], round(res[itr][4]*res[itr][5]/100)))\n",
    "#             meth_c_count += round(res[itr][4]*res[itr][5]/100)\n",
    "#             net_c_count += res[itr][5]\n",
    "#         elif end < res[itr][1]:\n",
    "#             ## the rest of sites are away from the window\n",
    "#             break\n",
    "\n",
    "#     unmeth_c_count = net_c_count - meth_c_count\n",
    "#     return meth_c_count, unmeth_c_count, freq, pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def findNDR(filtered_res, chr, win_len = 100, multiprocess=False, temp_loc=None):\n",
    "#     if multiprocess:\n",
    "#         if temp_loc is None:\n",
    "#             raise Exception('Input temp loc missing')\n",
    "\n",
    "#     start = filtered_res[0][1] - 90\n",
    "#     end = start + win_len\n",
    "#     step = 20\n",
    "#     pos_window = 0\n",
    "#     pos_bg_left = 0\n",
    "#     pos_bg_right = 0\n",
    "\n",
    "#     n = (filtered_res[-1][1] - filtered_res[0][1])/step\n",
    "#     progress_check = int(n/20)\n",
    "\n",
    "#     print(f'Finding NDR windows for {chr} with window len {win_len}')\n",
    "\n",
    "#     regions = []\n",
    "#     itr_count = 0\n",
    "#     curr_time = time.time()\n",
    "#     while (start < filtered_res[-1][1]):\n",
    "#         if itr_count != 0 and itr_count%progress_check == 0:\n",
    "#             print('progress for {} : {}% and time elapsed {} min'.format(chr, round(itr_count*100/n,2), round((time.time()-curr_time)/60,2)))\n",
    "        \n",
    "#         window = (start, end)\n",
    "#         meth_c_count, unmeth_c_count, freq, pos_window = getGCHcount_in_window(window, filtered_res, pos_window)\n",
    "\n",
    "#         if not meth_c_count > 0:\n",
    "#             start += step\n",
    "#             end += step\n",
    "#             itr_count += 1\n",
    "#             continue\n",
    "        \n",
    "#         window_bf_left = (start-4000, start)\n",
    "#         meth_c_count_bg_left, unmeth_c_count_bg_left, freq_bg_left, pos_bg_left = getGCHcount_in_window(window_bf_left, filtered_res, pos_bg_left)\n",
    "        \n",
    "#         window_bf_right = (end, end+4000)\n",
    "#         meth_c_count_bg_right, unmeth_c_count_bg_right, freq_bg_right, pos_bg_right = getGCHcount_in_window(window_bf_right, filtered_res, pos_bg_right)\n",
    "\n",
    "#         '''\n",
    "#                     Window(NDR)         background\n",
    "#             Meth    meth_c_count    meth_c_count_bg\n",
    "#             Unmeth  unmeth_c_count  unmeth_c_count_bg   \n",
    "#         '''\n",
    "\n",
    "#         meth_c_count_bg = meth_c_count_bg_left + meth_c_count_bg_right\n",
    "#         unmeth_c_count_bg = unmeth_c_count_bg_left + unmeth_c_count_bg_right\n",
    "\n",
    "#         ## same condition as above -- if condition for bg\n",
    "#         if not meth_c_count_bg > 0:\n",
    "#             start += step\n",
    "#             end += step\n",
    "#             itr_count += 1\n",
    "#             continue\n",
    "        \n",
    "#         table = np.array([[meth_c_count, meth_c_count_bg],\n",
    "#                         [unmeth_c_count, unmeth_c_count_bg]])\n",
    "        \n",
    "#         chi_test = chi2_contingency(table)\n",
    "\n",
    "#         if -np.log10(chi_test.pvalue) > 5:\n",
    "#             assert (start, end) == window\n",
    "#             window_ = (start, end, -np.log10(chi_test.pvalue))\n",
    "#             regions.append(window_)\n",
    "        \n",
    "#         start += step\n",
    "#         end += step\n",
    "#         itr_count += 1\n",
    "\n",
    "#     print(f'Merging found windows for {chr}')\n",
    "\n",
    "#     merged_regions = []\n",
    "\n",
    "#     n = len(regions)\n",
    "#     progress_check = int(n/10)\n",
    "\n",
    "#     i = 0\n",
    "#     curr_time = time.time()\n",
    "#     while i < n:\n",
    "#         # if i != 0 and i%progress_check == 0:\n",
    "#         #     print('progress : {}% and time elapsed {} min'.format(round(i*100/n,2), round((time.time()-curr_time)/60,2)))\n",
    "\n",
    "#         start, end, pval = regions[i]\n",
    "\n",
    "#         if i+1 < n:\n",
    "#             for j in range(i+1, n):\n",
    "#                 if regions[j][0] <= end:\n",
    "#                     end = regions[j][1]\n",
    "#                     pval = min(pval, regions[j][2])\n",
    "#                 else:\n",
    "#                     i = j\n",
    "#                     break\n",
    "        \n",
    "#             if j == n-1 and i != j:\n",
    "#                 i = n\n",
    "\n",
    "#             merged_regions.append((start, end, pval))\n",
    "#         else:\n",
    "#             i += 1\n",
    "#             assert i == n\n",
    "#             merged_regions.append((start, end, pval))\n",
    "\n",
    "#     if multiprocess:\n",
    "#         file_loc = temp_loc + 'temp.NDR.' + chr + '.bed'\n",
    "#         with open(file_loc, 'w') as fout:\n",
    "#             for reg in merged_regions:\n",
    "#                 temp = [chr, str(reg[0]), str(reg[1]), str(reg[2])]\n",
    "#                 fout.write('\\t'.join(temp) + '\\n')\n",
    "#     else:\n",
    "#         return merged_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chrs = ['chr' + str(c) for c in range(1, 23)] + ['chrX', 'chrY']\n",
    "# myprocess= []\n",
    "# win_len = 200\n",
    "# for chr in chrs:\n",
    "#     print(f'Run : {chr}')\n",
    "#     infile = data_path + 'GCH.filtered.sorted.bed'\n",
    "#     res = nome.filter_by_chr(infile, chrs=[chr], SILENT=True)\n",
    "#     print(f'no of reads for {chr} : {len(res)}')\n",
    "#     print(f'{chr} res check -', len(res), res[0], res[-1])\n",
    "\n",
    "#     myprocess.append(multiprocessing.Process(target=findNDR, args=(res, chr, win_len, True, data_path, )))\n",
    "#     myprocess[-1].start()\n",
    "\n",
    "# for p in myprocess:\n",
    "#     p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ndr_regions = []\n",
    "# chrs = ['chr' + str(c) for c in range(1, 23)] + ['chrX', 'chrY']\n",
    "# for chr in chrs:\n",
    "#     fpath = os.path.join(data_path, f'temp.NDR.{chr}.bed')\n",
    "#     with open(fpath, 'r') as fin:\n",
    "#         for line in fin:\n",
    "#             ndr_regions.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(ndr_regions), ndr_regions[0], ndr_regions[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outfile = data_path + 'NDRp.bed'\n",
    "# with open(outfile, 'w') as fout:\n",
    "#     for reg in ndr_regions:\n",
    "#         fout.write(reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chrs = ['chr' + str(c) for c in range(1, 23)] + ['chrX', 'chrY']\n",
    "# for chr in chrs:\n",
    "#     fpath = os.path.join(data_path, f'temp.NDR.{chr}.bed')\n",
    "#     os.remove(fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nome.sort_bed(data_path + 'NDRp.bed', data_path + 'NDRp.bed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_promoters_refGene(infile, outfile):\n",
    "    seen_coords = set()\n",
    "    itr = 0\n",
    "    with open(outfile, 'w') as fout:\n",
    "        with open(infile, 'r') as fin:\n",
    "            for line in fin:\n",
    "                if not line.startswith('#'):\n",
    "                    line_s = line.strip().split('\\t')\n",
    "\n",
    "                    refid = line_s[1]\n",
    "                    chrom = line_s[2]\n",
    "                    strand = line_s[3]\n",
    "                    txStart = int(line_s[4])\n",
    "                    txEnd = int(line_s[5])\n",
    "                    cdsStart = int(line_s[6])\n",
    "                    cdsEnd = int(line_s[7])\n",
    "                    geneName = ''.join(c for c in line_s[12] if c.isalnum())\n",
    "\n",
    "                    coords = chrom + str(txStart) + str(txEnd) + strand\n",
    "                    if coords not in seen_coords:\n",
    "                        seen_coords.add(coords)\n",
    "\n",
    "                        promo_start = 2000\n",
    "                        promo_end = 1000\n",
    "\n",
    "                        if strand == \"+\":\n",
    "                            promoter_start = txStart - promo_start\n",
    "                            promoter_end = txStart + promo_end\n",
    "                        else:\n",
    "                            promoter_start = txEnd - promo_end\n",
    "                            promoter_end = txEnd + promo_start\n",
    "                        \n",
    "                        if promoter_start < 0:\n",
    "                                promoter_start = 0\n",
    "\n",
    "                        if cdsStart != cdsEnd and geneName[0:3] != 'MIR' and geneName[0:3] != 'SNO' and '_' not in chrom:\n",
    "                            fout.write('\\t'.join([str(s) for s in [chrom, promoter_start, promoter_end, refid, geneName, txStart, txEnd, strand]]) + '\\n')\n",
    "                            itr += 1\n",
    "\n",
    "    print('no of promoters defined :', itr)\n",
    "    print('promoters saved to {}'.format(outfile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_introns_refGene(infile, outfile, anchor=1, pos='start'):\n",
    "    seen_coords = set()\n",
    "    itr = 0\n",
    "    with open(outfile, 'w') as fout:\n",
    "        with open(infile, 'r') as fin:\n",
    "            for line in fin:\n",
    "                if not line.startswith('#'):\n",
    "                    line_s = line.strip().split('\\t')\n",
    "\n",
    "                    refid = line_s[1]\n",
    "                    chrom = line_s[2]\n",
    "                    strand = line_s[3]\n",
    "                    txStart = int(line_s[4])\n",
    "                    txEnd = int(line_s[5])\n",
    "                    cdsStart = int(line_s[6])\n",
    "                    cdsEnd = int(line_s[7])\n",
    "                    geneName = ''.join(c for c in line_s[12] if c.isalnum())\n",
    "\n",
    "                    coords = chrom + str(txStart) + str(txEnd) + strand\n",
    "                    if coords not in seen_coords:\n",
    "                        seen_coords.add(coords)\n",
    "\n",
    "                        if cdsStart != cdsEnd and geneName[0:3] != 'MIR' and geneName[0:3] != 'SNO' and '_' not in chrom:\n",
    "                            assert line_s[9].endswith(',')\n",
    "                            assert line_s[10].endswith(',')\n",
    "\n",
    "                            exon_starts = np.array(list(map(int, line_s[9][:-1].strip().split(','))))\n",
    "                            exon_ends = np.array(list(map(int, line_s[10][:-1].strip().split(','))))\n",
    "\n",
    "                            assert exon_starts.shape == exon_ends.shape\n",
    "\n",
    "                            intron_starts = exon_ends[:-1].copy()\n",
    "                            intron_ends = exon_starts[1:].copy()\n",
    "\n",
    "                            assert np.all((intron_ends - intron_starts) >= 0)\n",
    "\n",
    "                            for i, (start, end) in enumerate(zip(intron_starts, intron_ends)):\n",
    "                                if i+1 == anchor:\n",
    "                                    if end > start:\n",
    "                                        start_offset = 2000\n",
    "                                        end_offset = 1000\n",
    "\n",
    "                                        if pos == 'start':\n",
    "                                            if strand == \"+\":\n",
    "                                                intron_start = start - start_offset\n",
    "                                                intron_end = start + end_offset\n",
    "                                            else:\n",
    "                                                intron_start = end - end_offset\n",
    "                                                intron_end = end + start_offset\n",
    "                                        \n",
    "                                        elif pos == 'end':\n",
    "                                            if strand == \"+\":\n",
    "                                                intron_start = end - start_offset\n",
    "                                                intron_end = end + end_offset\n",
    "                                            else:\n",
    "                                                intron_start = start - end_offset\n",
    "                                                intron_end = start + start_offset\n",
    "                                            \n",
    "                                        if intron_start < 0:\n",
    "                                                intron_start = 0\n",
    "\n",
    "                                        # print('\\t'.join([str(s) for s in [chrom, intron_start, intron_end, refid, geneName, txStart, txEnd, strand]]) + '\\n')\n",
    "                                        fout.write('\\t'.join([str(s) for s in [chrom, intron_start, intron_end, refid, geneName, txStart, txEnd, strand]]) + '\\n')\n",
    "                                        itr += 1\n",
    "\n",
    "                                    break\n",
    "\n",
    "    print('no of introns defined :', itr)\n",
    "    print('introns saved to {}'.format(outfile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = data_path + 'refGene'\n",
    "outfile = tmp_path + 'refGene.regions.bed'\n",
    "# get_promoters_refGene(infile, outfile) # for promoters\n",
    "get_introns_refGene(infile, outfile, anchor=2, pos='start') # for introns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## nucleotide added here\n",
    "def filter_bed_files(infile, outfile, min_cov=3):\n",
    "    chroms_seen = set()\n",
    "    non_std_chroms = set()\n",
    "    chroms = ['chr' + str(i) for i in range(1,23)] + ['chrX', 'chrY']\n",
    "\n",
    "    n = 0\n",
    "    with open(infile, 'r') as fin:\n",
    "        n = sum(1 for _ in fin)\n",
    "\n",
    "    progress_check = int(n/10)\n",
    "    itr = 0\n",
    "    with open(outfile, 'w') as fout:\n",
    "        with open(infile, 'r') as fin:\n",
    "            print('start traversing bed file ', infile, 'n = ', n)\n",
    "            curr_time = time.time()\n",
    "            for line in fin:\n",
    "                if itr != 0 and itr%progress_check == 0:\n",
    "                    print('progress : {}% and time elapsed {} min'.format(round(itr*100/n,2), round((time.time()-curr_time)/60,2)))\n",
    "\n",
    "                itr += 1\n",
    "                if not line.startswith('track'):\n",
    "                    line_s = line.strip().split('\\t')\n",
    "\n",
    "                    assert len(line_s) == 11\n",
    "                    \n",
    "                    chrom = 'chr' + line_s[0]\n",
    "                    if chrom in chroms:\n",
    "                        chroms_seen.add(chrom)\n",
    "\n",
    "                        start = int(line_s[1])\n",
    "                        end = int(line_s[2])\n",
    "                        methyl_rate = float(line_s[3])\n",
    "                        coverage = int(line_s[4])\n",
    "                        strand = line_s[5]\n",
    "                        nt = \"G\" if strand == \"-\" else \"C\"\n",
    "\n",
    "                        if coverage >= min_cov:\n",
    "                            fout.write('\\t'.join([str(x) for x in [chrom, start, end, strand, methyl_rate, coverage, nt]]) + '\\n')\n",
    "                    else:\n",
    "                        if chrom not in non_std_chroms:\n",
    "                            non_std_chroms.add(chrom)\n",
    "\n",
    "    assert len(chroms_seen) == 24\n",
    "\n",
    "    print('filered bed file with min coverage {} and saved to {}'.format(min_cov, outfile))\n",
    "    print('Non standard chrs seen : ', non_std_chroms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# infile = data_path + 'cpg.raw.sort.GCH.bed'\n",
    "# outfile = data_path + 'GCH.filtered.bed'\n",
    "\n",
    "# filter_bed_files(infile, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# infile = data_path + 'cpg.raw.sort.HCG.bed'\n",
    "# outfile = data_path + 'HCG.filtered.bed'\n",
    "\n",
    "# filter_bed_files(infile, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "def sort_bed(infile):\n",
    "    '''\n",
    "        sort -k1,1V -k2,2n /loc/GCH.filtered.bed > /loc/sorted.bed\n",
    "    '''\n",
    "    res = subprocess.run(['sort', '-k1,1V', '-k2,2n', f'{infile}'], capture_output=True, text=True)\n",
    "\n",
    "    outfile = infile.replace('.bed', '.sorted.bed')\n",
    "    if res.returncode == 0:\n",
    "        with open(outfile, 'w') as fout:\n",
    "            fout.write(res.stdout)\n",
    "    else:\n",
    "        print('error in sorting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort_bed(data_path + 'GCH.filtered.bed')\n",
    "# sort_bed(data_path + 'HCG.filtered.bed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_bed(tmp_path + 'refGene.regions.bed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersect_bed(file1, file2, outfile):\n",
    "    '''\n",
    "        bedtools intersect -a fa -b fb -wa -wb -sorted\n",
    "    '''\n",
    "    res = subprocess.run(['bedtools', 'intersect', '-a', f'{file1}', '-b', f'{file2}', '-wa', '-wb', '-sorted'],\n",
    "                          capture_output=True, text=True)\n",
    "\n",
    "    if res.returncode == 0:\n",
    "        with open(outfile, 'w') as fout:\n",
    "            fout.write(res.stdout)\n",
    "    else:\n",
    "        print('error in intersect')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "promoters_sorted = tmp_path + 'refGene.regions.sorted.bed'\n",
    "gch_sorted = data_path + 'GCH.filtered.sorted.bed'\n",
    "outfile = tmp_path + 'GCH.regions.intersect.bed'\n",
    "\n",
    "intersect_bed(promoters_sorted, gch_sorted, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "promoters_sorted = tmp_path + 'refGene.regions.sorted.bed'\n",
    "gch_sorted = data_path + 'HCG.filtered.sorted.bed'\n",
    "outfile = tmp_path + 'HCG.regions.intersect.bed'\n",
    "\n",
    "intersect_bed(promoters_sorted, gch_sorted, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sizes are different from directly loading the intersect.bed using pandas\n",
    "# we are loosing some values\n",
    "def get_methylation(infile, region='region'):\n",
    "    inter_dict = dict()\n",
    "    seen_ids = set()\n",
    "\n",
    "    with open(infile) as f:\n",
    "        for line in f:\n",
    "            line_s = line.strip().split('\\t')\n",
    "\n",
    "            chrom = line_s[0]            \n",
    "            region_start = int(line_s[1])\n",
    "            region_end = int(line_s[2])\n",
    "            refid = line_s[3]\n",
    "            gene_name = line_s[4]\n",
    "            TSS = int(line_s[5])\n",
    "            TES = int(line_s[6])\n",
    "            strand = line_s[7]\n",
    "            meth_start = int(line_s[9])\n",
    "            meth_end = int(line_s[10])\n",
    "            meth_rate = float(line_s[12])\n",
    "            coverage = int(line_s[13])\n",
    "            nt = line_s[14]\n",
    "\n",
    "            dict_id = refid + \"-\" + str(region_start)\n",
    "            \n",
    "            ## We are checking + and -ve strands based on promoter\n",
    "            if strand == \"+\":\n",
    "                intron_abs_pos = meth_start - region_start\n",
    "            if strand == \"-\":\n",
    "                intron_abs_pos = region_end - meth_end\n",
    "        \n",
    "            rel_pos = intron_abs_pos - 2000\n",
    "        \n",
    "            if dict_id not in seen_ids:\n",
    "                seen_ids.add(dict_id)\n",
    "                inter_dict[dict_id] = dict()\n",
    "            \n",
    "            inter_dict[dict_id][meth_start] = dict()\n",
    "            \n",
    "            inter_dict[dict_id][meth_start][\"chrom\"] = chrom\n",
    "            inter_dict[dict_id][meth_start][f\"{region}_start\"] = region_start\n",
    "            inter_dict[dict_id][meth_start][f\"{region}_end\"] = region_end\n",
    "            inter_dict[dict_id][meth_start][\"gene_name\"] = gene_name\n",
    "            inter_dict[dict_id][meth_start][\"TSS\"] = TSS\n",
    "            inter_dict[dict_id][meth_start][\"TES\"] = TES\n",
    "            inter_dict[dict_id][meth_start][\"strand\"] = strand\n",
    "            \n",
    "            inter_dict[dict_id][meth_start][\"meth_start_genome\"] = meth_start\n",
    "            inter_dict[dict_id][meth_start][\"meth_end_genome\"] = meth_end\n",
    "            inter_dict[dict_id][meth_start][\"meth_pos_abs\"] = intron_abs_pos\n",
    "            inter_dict[dict_id][meth_start][\"meth_pos_rel\"] = rel_pos\n",
    "                        \n",
    "            inter_dict[dict_id][meth_start][\"meth_rate\"] = meth_rate\n",
    "            inter_dict[dict_id][meth_start][\"coverage\"] = coverage\n",
    "            inter_dict[dict_id][meth_start][\"nt\"] = nt\n",
    "\n",
    "    column_names = ['trans_id', 'refid', 'gene_name', 'chrom', f'{region}_start', f'{region}_end', \n",
    "                    'TSS', 'TES', 'strand', 'meth_start_genome', 'meth_end_genome', 'meth_pos_abs',\n",
    "                    'meth_pos_rel', 'meth_rate', 'coverage', 'nt']\n",
    "\n",
    "    info_dict = dict()\n",
    "    for col in column_names:\n",
    "        info_dict[col] = []\n",
    "\n",
    "    ## Can create a filter for no of GCH or HCG in a promoter\n",
    "    for dict_id in inter_dict.keys():\n",
    "        refid = dict_id.split(\"-\")[0]\n",
    "        for promo_start in inter_dict[dict_id].keys():\n",
    "            info_dict[\"trans_id\"].append(dict_id)\n",
    "            info_dict[\"refid\"].append(refid)\n",
    "            info_dict[\"gene_name\"].append(inter_dict[dict_id][promo_start][\"gene_name\"])\n",
    "            info_dict[\"chrom\"].append(inter_dict[dict_id][promo_start][\"chrom\"])\n",
    "            info_dict[f\"{region}_start\"].append(inter_dict[dict_id][promo_start][f\"{region}_start\"])\n",
    "            info_dict[f\"{region}_end\"].append(inter_dict[dict_id][promo_start][f\"{region}_end\"])\n",
    "            info_dict[\"TSS\"].append(inter_dict[dict_id][promo_start][\"TSS\"])\n",
    "            info_dict[\"TES\"].append(inter_dict[dict_id][promo_start][\"TES\"])\n",
    "            info_dict[\"strand\"].append(inter_dict[dict_id][promo_start][\"strand\"])\n",
    "            \n",
    "            info_dict[\"meth_start_genome\"].append(inter_dict[dict_id][promo_start][\"meth_start_genome\"])\n",
    "            info_dict[\"meth_end_genome\"].append(inter_dict[dict_id][promo_start][\"meth_end_genome\"])\n",
    "            info_dict[\"meth_pos_abs\"].append(inter_dict[dict_id][promo_start][\"meth_pos_abs\"])\n",
    "            info_dict[\"meth_pos_rel\"].append(inter_dict[dict_id][promo_start][\"meth_pos_rel\"])\n",
    "            \n",
    "            info_dict[\"meth_rate\"].append(inter_dict[dict_id][promo_start][\"meth_rate\"])\n",
    "            info_dict[\"coverage\"].append(inter_dict[dict_id][promo_start][\"coverage\"])\n",
    "            info_dict[\"nt\"].append(inter_dict[dict_id][promo_start][\"nt\"])\n",
    "\n",
    "    # Built dataframe\n",
    "    df = pd.DataFrame(0, index = np.arange(len(info_dict[\"refid\"])), columns = column_names)\n",
    "    for feat in column_names:\n",
    "        df[feat] = info_dict[feat]  \n",
    "        \n",
    "    df = df.sort_values(by = ['chrom', f'{region}_start'], ascending = [True, True])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = tmp_path + 'GCH.regions.intersect.bed'\n",
    "df_GCH_intersect = get_methylation(infile, region=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_GCH_intersect.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## some random analysis\n",
    "from collections import defaultdict\n",
    "chr_groups = df_GCH_intersect.groupby(by='chrom')\n",
    "methylation_dist = defaultdict(list)\n",
    "for chr_group in chr_groups:\n",
    "    region_groups = chr_group[1].groupby(by=[f'{region}_start', f'{region}_end'])\n",
    "    for region_group in region_groups:\n",
    "        methylation_dist[chr_group[0]].append(region_group[1].shape[0])\n",
    "\n",
    "for key in methylation_dist:\n",
    "    _ = plt.hist(methylation_dist[key], label=key, alpha=0.5)\n",
    "\n",
    "plt.xlabel(f'no of GCH meth in {region} by chrom')\n",
    "plt.legend(ncol=4, labelspacing=0.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = tmp_path + 'HCG.regions.intersect.bed'\n",
    "df_HCG_intersect = get_methylation(infile, region=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## some random analysis\n",
    "from collections import defaultdict\n",
    "chr_groups = df_HCG_intersect.groupby(by='chrom')\n",
    "methylation_dist = defaultdict(list)\n",
    "for chr_group in chr_groups:\n",
    "    region_groups = chr_group[1].groupby(by=[f'{region}_start', f'{region}_end'])\n",
    "    for region_group in region_groups:\n",
    "        methylation_dist[chr_group[0]].append(region_group[1].shape[0])\n",
    "\n",
    "for key in methylation_dist:\n",
    "    _ = plt.hist(methylation_dist[key], label=key, alpha=0.5)\n",
    "\n",
    "plt.xlabel(f'no of HCG meth in {region} by chrom')\n",
    "plt.legend(ncol=4, labelspacing=0.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_avg_methylation_levels(df, context, select_genes=[], fig = True, c = 'grey', label = None, rel=False, inter_start=None, inter_end=None):\n",
    "    \n",
    "    if len(select_genes) == 0: \n",
    "        all_meth_pos_rel = list(df['meth_pos_rel'])\n",
    "        all_meth_rate = list(df['meth_rate'])\n",
    "        all_coverage = list(df['coverage'])\n",
    "\n",
    "        assert len(all_meth_pos_rel) == len(all_meth_rate) == len(all_coverage)\n",
    "\n",
    "        av_dict = dict()\n",
    "        seen_pos = set()\n",
    "        for p in range(len(all_meth_pos_rel)):\n",
    "            rel_pos_x = all_meth_pos_rel[p]\n",
    "            meth_rate = all_meth_rate[p]\n",
    "            coverage = all_coverage[p]\n",
    "            \n",
    "            #AVERAGE\n",
    "            if rel_pos_x not in seen_pos:\n",
    "                seen_pos.add(rel_pos_x)\n",
    "                av_dict[rel_pos_x] = {}\n",
    "                av_dict[rel_pos_x]['meth'] = []\n",
    "                av_dict[rel_pos_x]['total'] = []\n",
    "            \n",
    "            if context == 'GCH':\n",
    "                av_dict[rel_pos_x]['meth'].append(coverage*(100-meth_rate)/100)\n",
    "                av_dict[rel_pos_x]['total'].append(coverage)\n",
    "            elif context == 'HCG':\n",
    "                av_dict[rel_pos_x]['meth'].append(meth_rate*coverage/100)\n",
    "                av_dict[rel_pos_x]['total'].append(coverage)\n",
    "            else:\n",
    "                print('Check context')\n",
    "                return\n",
    "    else:\n",
    "        av_dict = {}\n",
    "        seen_pos = set()\n",
    "        group = df[df['gene_name'].isin(select_genes)]\n",
    "        for rel_pos_x, meth_rate, coverage in zip(group['meth_pos_rel'], group['meth_rate'], group['coverage']):\n",
    "            if rel_pos_x not in seen_pos:\n",
    "                seen_pos.add(rel_pos_x)\n",
    "                av_dict[rel_pos_x] = {}\n",
    "                av_dict[rel_pos_x]['meth'] = []\n",
    "                av_dict[rel_pos_x]['total'] = []\n",
    "\n",
    "            if context == 'GCH':\n",
    "                av_dict[rel_pos_x]['meth'].append(coverage*(100-meth_rate)/100)\n",
    "                av_dict[rel_pos_x]['total'].append(coverage)\n",
    "            elif context == 'HCG':\n",
    "                av_dict[rel_pos_x]['meth'].append(meth_rate*coverage/100)\n",
    "                av_dict[rel_pos_x]['total'].append(coverage)\n",
    "            else:\n",
    "                print('Check context')\n",
    "                return\n",
    "            \n",
    "\n",
    "    if fig:\n",
    "        plt.figure(figsize=(15, 7), facecolor='w', edgecolor='k')\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    for rel_pos_x in sorted(av_dict.keys()):\n",
    "        if rel:\n",
    "            if rel_pos_x >= inter_start and rel_pos_x <= inter_end:\n",
    "                if len(av_dict[rel_pos_x]['meth']) >= 100: ## to remove artifact\n",
    "                    x.append(rel_pos_x)\n",
    "                    y.append(np.sum(av_dict[rel_pos_x]['meth'])*100/np.sum(av_dict[rel_pos_x]['total']))\n",
    "        else:\n",
    "            if len(av_dict[rel_pos_x]['meth']) >= 100: ## to remove artifact\n",
    "                x.append(rel_pos_x)\n",
    "                y.append(np.sum(av_dict[rel_pos_x]['meth'])*100/np.sum(av_dict[rel_pos_x]['total']))\n",
    "\n",
    "    if label is None:\n",
    "        plt.plot(x, y, \"-\", color=c, alpha=1.0)\n",
    "    else:\n",
    "        plt.plot(x, y, \"-\", color=c, label=label, alpha=0.7)\n",
    "        plt.legend()\n",
    "        \n",
    "    plt.xlabel(\"DNA position [bp]\")\n",
    "    plt.xlim(-2000,1000)\n",
    "\n",
    "    if context == 'GCH':\n",
    "        ylab = \"100-GpC methylation level\"\n",
    "    if context == 'HCG':\n",
    "        ylab = \"CpG methylation level\"\n",
    "    plt.ylabel(ylab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_avg_methylation_levels(df_GCH_intersect, 'GCH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_avg_methylation_levels(df_HCG_intersect, 'HCG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = tmp_path + 'HCG.regions.intersect.bed'\n",
    "cols = ['chrom', 'region_start', 'region_end', 'refid', 'gene_name', \n",
    "        'TSS', 'TES', 'strand', 'chrom_', 'meth_start_genome', 'meth_end_genome', \n",
    "        'strand_', 'meth_rate', 'coverage', 'nt']\n",
    "df_HCG_intersect_random = pd.read_csv(infile, sep='\\t', names=cols)\n",
    "df_HCG_intersect_random['meth_rate'] = df_HCG_intersect_random['meth_rate'].sample(frac=1).reset_index(drop=True)\n",
    "outfile = tmp_path + 'HCG.regions.intersect.random.bed'\n",
    "df_HCG_intersect_random.to_csv(outfile, sep='\\t', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = tmp_path + 'HCG.regions.intersect.random.bed'\n",
    "df_HCG_intersect_random = get_methylation(infile, region=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_avg_methylation_levels(df_HCG_intersect_random, 'HCG', fig=True, c='#333232', label='random')\n",
    "plot_avg_methylation_levels(df_HCG_intersect, 'HCG', fig=False, label='exp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_HCG_intersect_random.shape, df_HCG_intersect.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_CpG_CpG_dist(df, max_dist=20, c='grey'):\n",
    "    dist_list = []\n",
    "    chroms = ['chr' + str(i) for i in range(1,23)] + ['chrX', 'chrY']\n",
    "    for chrom in chroms:\n",
    "        #### ALL methylated pos\n",
    "        all_meth_pos = list(df.loc[(df[\"meth_rate\"] != 0) & \n",
    "                                   (df[\"chrom\"] == chrom) & \n",
    "                                   (df[\"nt\"] == \"C\")][\"meth_start_genome\"])\n",
    "        all_meth_pos_sorted = sorted(list(set(all_meth_pos))) # since mapped to promoter, CpG can be twice if promoter overlap, make set\n",
    "\n",
    "        for pos in range(len(all_meth_pos_sorted) - 1):\n",
    "            start = all_meth_pos_sorted[pos]\n",
    "            next_start = all_meth_pos_sorted[pos+1]\n",
    "            dist = next_start - start - 1 # is number of bases inbetween\n",
    "            \n",
    "            if dist <= max_dist:\n",
    "                dist_list.append(dist)\n",
    "\n",
    "    y = []\n",
    "    for r in range(max_dist+1):\n",
    "        freq = float(dist_list.count(r))/float(len(dist_list))*100\n",
    "        y.append(freq)\n",
    "\n",
    "\n",
    "    plt.figure(facecolor='w', edgecolor='k')\n",
    "\n",
    "    x = np.arange(len(y))\n",
    "    plt.bar(x, y, align='center', color=c)\n",
    "\n",
    "    plt.xlabel(\"Distance to next 5meC [bp]\")\n",
    "    plt.ylabel(\"Percentage [%]\")\n",
    "    plt.xlim(1, max_dist+1)\n",
    "    plt.xticks(x, range(max_dist+1))\n",
    "    plt.ylim(0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_CpG_CpG_dist(df_HCG_intersect)\n",
    "plot_CpG_CpG_dist(df_HCG_intersect_random, c='#333232')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "promoters_sorted = tmp_path + 'refGene.regions.sorted.bed'\n",
    "ndrfile = data_path + 'NDR.bed'\n",
    "outfile = tmp_path + 'NDR.regions.intersect.bed'\n",
    "intersect_bed(promoters_sorted, ndrfile, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "promoters_sorted = tmp_path + 'refGene.regions.sorted.bed'\n",
    "ndrfile = data_path + 'NOR.bed'\n",
    "outfile = tmp_path + 'NOR.regions.intersect.bed'\n",
    "intersect_bed(promoters_sorted, ndrfile, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nuc_positions(infile, region='region'):\n",
    "    column_names = [\"trans_id\", \"refid\", \"gene_name\", \"chrom\", f\"{region}_start\", f\"{region}_end\",\n",
    "                    \"TSS\", \"TES\", \"strand\", \"nuc_region_start_genome\", \"nuc_region_end_genome\",\n",
    "                    \"nuc_start_promo_abs\", \"nuc_end_promo_abs\", \"nuc_start_promo_rel\",\n",
    "                    \"nuc_end_promo_rel\", \"region_length\"]\n",
    "    \n",
    "    info_dict = dict()\n",
    "    for col in column_names:\n",
    "        info_dict[col] = []\n",
    "    \n",
    "    with open(infile) as fin:\n",
    "        for line in fin:\n",
    "            line_s = line.strip().split('\\t')\n",
    "\n",
    "            chrom = line_s[0]            \n",
    "            region_start = int(line_s[1])\n",
    "            region_end = int(line_s[2])\n",
    "            refid = line_s[3]\n",
    "            gene_name = line_s[4]\n",
    "            TSS = int(line_s[5])\n",
    "            TES = int(line_s[6])\n",
    "            strand = line_s[7]\n",
    "\n",
    "            nuc_region_start = int(line_s[9])\n",
    "            nuc_region_end = int(line_s[10])\n",
    "            \n",
    "\n",
    "            if nuc_region_start >= region_start and nuc_region_end <= region_end:    \n",
    "                if strand == \"+\":\n",
    "                    nuc_abs_start = nuc_region_start - region_start\n",
    "                    nuc_abs_end = nuc_region_end - region_start\n",
    "                    \n",
    "                if strand == \"-\":\n",
    "                    nuc_abs_end = region_end - nuc_region_start\n",
    "                    nuc_abs_start = region_end - nuc_region_end\n",
    "\n",
    "                rel_start = nuc_abs_start - 2000\n",
    "                rel_end = nuc_abs_end - 2000\n",
    "\n",
    "                info_dict[\"trans_id\"].append(refid+'-'+str(region_start))\n",
    "                info_dict[\"chrom\"].append(chrom)\n",
    "                info_dict[f\"{region}_start\"].append(region_start)\n",
    "                info_dict[f\"{region}_end\"].append(region_end)\n",
    "                info_dict[\"refid\"].append(refid)\n",
    "                info_dict[\"gene_name\"].append(gene_name)\n",
    "                info_dict[\"TSS\"].append(TSS)\n",
    "                info_dict[\"TES\"].append(TES)\n",
    "                info_dict[\"strand\"].append(strand)\n",
    "                \n",
    "                info_dict[\"nuc_region_start_genome\"].append(nuc_region_start)\n",
    "                info_dict[\"nuc_region_end_genome\"].append(nuc_region_end)\n",
    "                \n",
    "                info_dict[\"nuc_start_promo_abs\"].append(nuc_abs_start)\n",
    "                info_dict[\"nuc_end_promo_abs\"].append(nuc_abs_end)\n",
    "                \n",
    "                info_dict[\"nuc_start_promo_rel\"].append(rel_start)\n",
    "                info_dict[\"nuc_end_promo_rel\"].append(rel_end)\n",
    "                \n",
    "                info_dict[\"region_length\"].append(rel_end - rel_start)\n",
    "            \n",
    "            else:\n",
    "                # print('please check intersection file')\n",
    "                pass\n",
    "\n",
    "            \n",
    "    # Built dataframe\n",
    "    df = pd.DataFrame(0, index = np.arange(len(info_dict[\"refid\"])), columns = column_names)\n",
    "    for feat in column_names:\n",
    "        df[feat] = info_dict[feat]  \n",
    "        \n",
    "    df = df.sort_values(by = ['chrom', f'{region}_start'], ascending=[True, True])\n",
    "      \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = tmp_path + 'NDR.regions.intersect.bed'\n",
    "df_NDR_pos = get_nuc_positions(infile, region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NDR_pos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = tmp_path + 'NOR.regions.intersect.bed'\n",
    "df_NOR_pos = get_nuc_positions(infile, region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NOR_pos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NDR_pos.shape, df_NOR_pos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NDR_pos['trans_id'].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NOR_pos['trans_id'].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_start = -2000\n",
    "inter_end = 1000\n",
    "step = 200\n",
    "inter = range(inter_start,inter_end+1,step)\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.hist(df_NDR_pos['nuc_end_promo_rel'],  bins = 60, histtype='bar', density=False, label=\"End positions\", alpha = 0.8)  \n",
    "plt.hist(df_NDR_pos['nuc_start_promo_rel'], bins = 60, histtype='bar', density=False, label=\"Start positions\", alpha = 0.5)   \n",
    "\n",
    "plt.xlabel(\"DNA position [bp]\")\n",
    "plt.ylabel(\"Density\")\n",
    "\n",
    "plt.xlim(-2000,1000)\n",
    "plt.axvline(x=0, linestyle='dashed', linewidth=2, color='grey')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.hist(df_NDR_pos['region_length'], bins=30, histtype='bar', density=False)  \n",
    "\n",
    "plt.xlabel(\"NDR length [bp]\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_start = -2000\n",
    "inter_end = 1000\n",
    "step = 200\n",
    "inter = range(inter_start,inter_end+1,step)\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.hist(df_NOR_pos['nuc_end_promo_rel'],  bins = 60, histtype='bar', density=False, label=\"End positions\", alpha = 0.8)  \n",
    "plt.hist(df_NOR_pos['nuc_start_promo_rel'], bins = 60, histtype='bar', density=False, label=\"Start positions\", alpha = 0.5)   \n",
    "\n",
    "plt.xlabel(\"DNA position [bp]\")\n",
    "plt.ylabel(\"Density\")\n",
    "\n",
    "plt.xlim(-2000,1000)\n",
    "plt.axvline(x=0, linestyle='dashed', linewidth=2, color='grey')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.hist(df_NOR_pos['region_length'], bins=30, histtype='bar', density=False)  \n",
    "\n",
    "plt.xlabel(\"HNDR length [bp]\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.hist((df_NDR_pos['nuc_start_promo_rel']+df_NDR_pos['nuc_end_promo_rel'])/2, \n",
    "           bins=60, histtype='bar', density=False, alpha=0.8)  \n",
    "\n",
    "ax.set_xlabel(\"relative centre\")\n",
    "ax.set_ylabel(\"no of LNDRs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.hist((df_NOR_pos['nuc_start_promo_rel']+df_NOR_pos['nuc_end_promo_rel'])/2, \n",
    "           bins=60, histtype='bar', density=False, alpha=0.8)  \n",
    "\n",
    "ax.set_xlabel(\"relative centre\")\n",
    "ax.set_ylabel(\"no of HNDRs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clash_dict_loc = steric_path + 'clash_dict'\n",
    "info_dict_loc = steric_path + 'info_nbr_dict'\n",
    "nome.plot_nbr_clashs(steric_path, clash_dict_loc, info_dict_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "promo_NDR_file = tmp_path + 'NDR.regions.intersect.bed'\n",
    "promo_HCG_file = tmp_path + 'HCG.regions.intersect.bed'\n",
    "outfile = tmp_path + 'regions.NDR.HCG.intersect.bed'\n",
    "intersect_bed(promo_NDR_file, promo_HCG_file, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "promo_NDR_file = tmp_path + 'NDR.regions.intersect.bed'\n",
    "promo_HCG_file = tmp_path + 'HCG.regions.intersect.random.bed'\n",
    "outfile = tmp_path + 'regions.NDR.HCG.random.intersect.bed'\n",
    "intersect_bed(promo_NDR_file, promo_HCG_file, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "promo_NDR_file = tmp_path + 'NOR.regions.intersect.bed'\n",
    "promo_HCG_file = tmp_path + 'HCG.regions.intersect.bed'\n",
    "outfile = tmp_path + 'regions.NOR.HCG.intersect.bed'\n",
    "intersect_bed(promo_NDR_file, promo_HCG_file, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "promo_NDR_file = tmp_path + 'NOR.regions.intersect.bed'\n",
    "promo_HCG_file = tmp_path + 'HCG.regions.intersect.random.bed'\n",
    "outfile = tmp_path + 'regions.NOR.HCG.random.intersect.bed'\n",
    "intersect_bed(promo_NDR_file, promo_HCG_file, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nuc_pos_methylation(infile, region='region'):\n",
    "    column_names = [\"trans_id\", \"refid\", \"gene_name\", \"chrom\", f\"{region}_start\", f\"{region}_end\",\n",
    "                    \"TSS\", \"TES\", \"strand\", \"nuc_region_start_genome\", \"nuc_region_end_genome\",\n",
    "                    \"nuc_region_length\", \"meth_start_genome\", \"meth_end_genome\", \"meth_rate\", \"nt\"]\n",
    "    \n",
    "    info_dict = dict()\n",
    "    for col in column_names:\n",
    "        info_dict[col] = []\n",
    "    \n",
    "    with open(infile, 'r') as fin:\n",
    "        for line in fin:\n",
    "            line_s = line.strip().split('\\t')\n",
    "\n",
    "            chrom = line_s[0]            \n",
    "            region_start = int(line_s[1])\n",
    "            region_end = int(line_s[2])\n",
    "            refid = line_s[3]\n",
    "            gene_name = line_s[4]\n",
    "            TSS = int(line_s[5])\n",
    "            TES = int(line_s[6])\n",
    "            strand = line_s[7]\n",
    "            \n",
    "            nuc_region_start = int(line_s[9])\n",
    "            nuc_region_end = int(line_s[10])\n",
    "            \n",
    "            meth_start = int(line_s[20])\n",
    "            meth_end = int(line_s[21])\n",
    "            meth_rate = float(line_s[23])\n",
    "            nt = line_s[25]\n",
    "            \n",
    "            if nuc_region_start >= region_start and nuc_region_end <= region_end:\n",
    "                info_dict[\"trans_id\"].append(refid + \"-\" + str(region_start))\n",
    "                info_dict[\"chrom\"].append(chrom)\n",
    "                info_dict[f\"{region}_start\"].append(region_start)\n",
    "                info_dict[f\"{region}_end\"].append(region_end)\n",
    "                info_dict[\"refid\"].append(refid)\n",
    "                info_dict[\"gene_name\"].append(gene_name)\n",
    "                info_dict[\"TSS\"].append(TSS)\n",
    "                info_dict[\"TES\"].append(TES)\n",
    "                info_dict[\"strand\"].append(strand)\n",
    "                \n",
    "                info_dict[\"nuc_region_start_genome\"].append(nuc_region_start)\n",
    "                info_dict[\"nuc_region_end_genome\"].append(nuc_region_end)                \n",
    "                info_dict[\"nuc_region_length\"].append(nuc_region_end-nuc_region_start)\n",
    "                \n",
    "                info_dict[\"meth_start_genome\"].append(meth_start)\n",
    "                info_dict[\"meth_end_genome\"].append(meth_end)\n",
    "                info_dict[\"meth_rate\"].append(meth_rate)\n",
    "                info_dict[\"nt\"].append(nt)\n",
    "\n",
    "            \n",
    "    #Built dataframe\n",
    "    df = pd.DataFrame(0, index = np.arange(len(info_dict[\"refid\"])), columns = column_names)\n",
    "    for feat in column_names:\n",
    "        df[feat] = info_dict[feat]  \n",
    "        \n",
    "    df = df.sort_values(by=['chrom', f'{region}_start'], ascending=[True, True])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_clash_dict(x_y_clash_dict):\n",
    "    min_clash = min(x_y_clash_dict.values())\n",
    "    max_clash = max(x_y_clash_dict.values())\n",
    "\n",
    "    x_y_clash_dict_norm = {k: (float(v-min_clash)/float(max_clash-min_clash))*100 for k, v in x_y_clash_dict.items()}\n",
    "    return x_y_clash_dict_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = steric_path + 'x_y_dict'\n",
    "with open(infile, 'rb') as fin:\n",
    "    x_y_clash_dict = pickle.load(fin)\n",
    "\n",
    "x_y_clash_dict_norm = normalize_clash_dict(x_y_clash_dict)\n",
    "\n",
    "meth_thres_range = [0, 10, 20]\n",
    "clash_thres_range = [5, 10, 20, 50]\n",
    "\n",
    "params = []\n",
    "for clash_thres in clash_thres_range:\n",
    "    for meth_thres in meth_thres_range:\n",
    "        k = \"c\" + str(clash_thres) + \"m\" + str(meth_thres)\n",
    "        params.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = tmp_path + 'regions.NDR.HCG.intersect.bed'\n",
    "df_NDR = get_nuc_pos_methylation(infile, region=region)\n",
    "\n",
    "infile = tmp_path + 'regions.NDR.HCG.random.intersect.bed'\n",
    "df_NDR_random = get_nuc_pos_methylation(infile, region=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NDR.shape, df_NDR_random.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NDR.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### only in a small fraction of these methyl regions are actually inside NDRs\n",
    "np.logical_and(df_NDR['meth_start_genome'] > df_NDR['nuc_region_start_genome'], df_NDR['meth_start_genome'] < df_NDR['nuc_region_end_genome']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = tmp_path + 'regions.NOR.HCG.intersect.bed'\n",
    "df_NOR = get_nuc_pos_methylation(infile, region=region)\n",
    "\n",
    "infile = tmp_path + 'regions.NOR.HCG.random.intersect.bed'\n",
    "df_NOR_random = get_nuc_pos_methylation(infile, region=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NOR.shape, df_NOR_random.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NOR.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### only in a small fraction of these methyl regions are actually inside NDRs\n",
    "np.logical_and(df_NOR['meth_start_genome'] > df_NOR['nuc_region_start_genome'], df_NOR['meth_start_genome'] < df_NOR['nuc_region_end_genome']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sliding_windows_file(df_promo_nuc_WGBS, x_y_clash_dict_norm, mask=True, region='region'):\n",
    "    if mask:\n",
    "        pos_true = pd.DataFrame([df_promo_nuc_WGBS['meth_start_genome'] > df_promo_nuc_WGBS['nuc_region_start_genome'], \n",
    "                                 df_promo_nuc_WGBS['meth_start_genome'] < df_promo_nuc_WGBS['nuc_region_end_genome'], \n",
    "                                 df_promo_nuc_WGBS['strand'] == '+']).T.all(axis=1)\n",
    "        neg_true = pd.DataFrame([df_promo_nuc_WGBS['meth_end_genome'] > df_promo_nuc_WGBS['nuc_region_start_genome'], \n",
    "                                 df_promo_nuc_WGBS['meth_end_genome'] < df_promo_nuc_WGBS['nuc_region_end_genome'], \n",
    "                                 df_promo_nuc_WGBS['strand'] == '-']).T.all(axis=1)\n",
    "        df_promo_nuc_WGBS = df_promo_nuc_WGBS[np.logical_or(pos_true, neg_true)]\n",
    "\n",
    "\n",
    "    column_names = [\"trans_id\", \"refid\", \"NOR_nbr\", \"window_nbr\", \"nbr_meth_CpGs\", \n",
    "                    \"nuc_region_length\", \"nuc_rel_center\", \"meth_rates_window\"] \n",
    "    info_dict = dict()\n",
    "    for col in column_names:\n",
    "        info_dict[col] = []\n",
    "        \n",
    "    all_nuc_pos = x_y_clash_dict_norm.keys()\n",
    "    nbr_bases_nuc = len(all_nuc_pos)\n",
    "    \n",
    "    all_trans_ids = list(set(list(df_promo_nuc_WGBS[\"trans_id\"])))\n",
    "    \n",
    "    c = 0\n",
    "    for trans_id in tqdm(all_trans_ids):\n",
    "        refid = trans_id.split(\"-\")[0]\n",
    "        c += 1\n",
    "        \n",
    "        df_WGBS_tmp = df_promo_nuc_WGBS.loc[df_promo_nuc_WGBS[\"trans_id\"] == trans_id]\n",
    "        \n",
    "        NOR_number = 1\n",
    "        nuc_region_starts = list(set(list(df_WGBS_tmp[\"nuc_region_start_genome\"])))\n",
    "        for NOR_start in nuc_region_starts:\n",
    "            df_NOR_tmp = df_WGBS_tmp.loc[df_WGBS_tmp[\"nuc_region_start_genome\"] == NOR_start]\n",
    "            \n",
    "            start = NOR_start\n",
    "            win_nbr = 1\n",
    "                    \n",
    "            list_meth_positions = list(df_NOR_tmp[\"meth_start_genome\"])\n",
    "            list_meth_rates = list(df_NOR_tmp[\"meth_rate\"])\n",
    "            meth_dict_promoter = dict(zip(list_meth_positions, list_meth_rates))\n",
    "    \n",
    "            NOR_end = list(df_NOR_tmp[\"nuc_region_end_genome\"])[0]\n",
    "\n",
    "            assert df_NOR_tmp[f\"{region}_start\"].unique().shape[0] == 1\n",
    "            region_start = df_NOR_tmp[f\"{region}_start\"].unique()[0]\n",
    "            assert df_NOR_tmp[f\"{region}_end\"].unique().shape[0] == 1\n",
    "            region_end = df_NOR_tmp[f\"{region}_end\"].unique()[0]\n",
    "            assert df_NOR_tmp[f\"strand\"].unique().shape[0] == 1\n",
    "            strand = df_NOR_tmp[f\"strand\"].unique()[0]\n",
    "\n",
    "            if NOR_start >= region_start and NOR_end <= region_end:    \n",
    "                if strand == \"+\":\n",
    "                    nuc_abs_start = NOR_start - region_start\n",
    "                    nuc_abs_end = NOR_end - region_start\n",
    "                    \n",
    "                if strand == \"-\":\n",
    "                    nuc_abs_end = region_end - NOR_start\n",
    "                    nuc_abs_start = region_end - NOR_end\n",
    "\n",
    "                rel_start = nuc_abs_start - 2000\n",
    "                rel_end = nuc_abs_end - 2000\n",
    "            else:\n",
    "                raise Exception(\"problem\")\n",
    "            \n",
    "            while start + nbr_bases_nuc - 1 <= NOR_end:\n",
    "                #get relative and absolute position+methylation\n",
    "                window_start = start\n",
    "                window_end = window_start+nbr_bases_nuc-1\n",
    "                \n",
    "                meth_in_window_tmp = dict()\n",
    "                for meth_start_genome in meth_dict_promoter.keys():\n",
    "                    if (window_start <= meth_start_genome) & (meth_start_genome <= window_end):\n",
    "                        rel_pos = meth_start_genome-window_start+1\n",
    "                        \n",
    "                        meth_rate = meth_dict_promoter[meth_start_genome]\n",
    "                        meth_in_window_tmp[rel_pos] = meth_rate\n",
    "                \n",
    "                if len(meth_in_window_tmp) != 0:\n",
    "                    #exp\n",
    "                    info_dict[\"trans_id\"].append(trans_id)\n",
    "                    info_dict[\"refid\"].append(refid)\n",
    "                    info_dict[\"NOR_nbr\"].append(NOR_number)\n",
    "                    info_dict[\"window_nbr\"].append(win_nbr)\n",
    "                    info_dict[\"nbr_meth_CpGs\"].append(len(meth_in_window_tmp.keys()))\n",
    "                    info_dict[\"nuc_region_length\"].append(np.abs(NOR_end-NOR_start)+1)\n",
    "                    info_dict[\"nuc_rel_center\"].append((rel_start+rel_end)/2)\n",
    "                    info_dict[\"meth_rates_window\"].append(meth_in_window_tmp)\n",
    "                \n",
    "                start += 1\n",
    "                win_nbr += 1\n",
    "        \n",
    "            NOR_number += 1\n",
    "                \n",
    "                \n",
    "    #Built dataframe\n",
    "    df = pd.DataFrame(0, index = np.arange(len(info_dict[\"trans_id\"])),columns = column_names)\n",
    "    for feat in column_names:\n",
    "        df[feat] = info_dict[feat]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## takes time try mask = False\n",
    "df_NDR_sliding_windows = make_sliding_windows_file(df_NDR, x_y_clash_dict_norm, region=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NDR_sliding_windows_random = make_sliding_windows_file(df_NDR_random, x_y_clash_dict_norm, region=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NDR_sliding_windows.shape, df_NDR_sliding_windows_random.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NDR_sliding_windows.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## takes time try mask = False\n",
    "df_NOR_sliding_windows = make_sliding_windows_file(df_NOR, x_y_clash_dict_norm, region=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NOR_sliding_windows_random = make_sliding_windows_file(df_NOR_random, x_y_clash_dict_norm, region=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NOR_sliding_windows.shape, df_NOR_sliding_windows_random.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NOR_sliding_windows.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = df_NDR_sliding_windows.groupby(by='trans_id')\n",
    "\n",
    "nor_nbr = []\n",
    "for group in groups:\n",
    "    nor_nbr.append(group[1]['NOR_nbr'].unique().shape[0])\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.scatter(np.arange(df_NDR_sliding_windows['trans_id'].unique().shape[0]), nor_nbr, marker='.', alpha=0.3)\n",
    "\n",
    "groups = df_NOR_sliding_windows.groupby(by='trans_id')\n",
    "\n",
    "nor_nbr = []\n",
    "for group in groups:\n",
    "    nor_nbr.append(group[1]['NOR_nbr'].unique().shape[0])\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.scatter(np.arange(df_NOR_sliding_windows['trans_id'].unique().shape[0]), nor_nbr, marker='.', alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "_ = plt.hist(df_NDR_sliding_windows['nbr_meth_CpGs'])\n",
    "_ = plt.hist(df_NDR_sliding_windows_random['nbr_meth_CpGs'])\n",
    "_ = plt.xlabel('LNDR sliding windows no of CpGs')\n",
    "\n",
    "plt.figure()\n",
    "_ = plt.hist(df_NOR_sliding_windows['nbr_meth_CpGs'])\n",
    "_ = plt.hist(df_NOR_sliding_windows_random['nbr_meth_CpGs'])\n",
    "_ = plt.xlabel('HNDR sliding windows no of CpGs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(df_NDR_sliding_windows['nuc_rel_center'], df_NDR_sliding_windows['nbr_meth_CpGs'], \n",
    "            marker='.', alpha=0.3)\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(df_NOR_sliding_windows['nuc_rel_center'], df_NOR_sliding_windows['nbr_meth_CpGs'], \n",
    "            marker='.', alpha=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def calc_perc_exp_clash_ident(x_y_clash_dict_norm, meth_in_window_tmp, meth_thres, clash_thres):    \n",
    "    count_ident = 0\n",
    "    cpg_positions = meth_in_window_tmp.keys()\n",
    "    for meth_pos in cpg_positions:\n",
    "        meth_rate = meth_in_window_tmp[meth_pos]\n",
    "        clash_perc = x_y_clash_dict_norm[meth_pos] \n",
    "        \n",
    "        if meth_rate > meth_thres:\n",
    "            if clash_perc <= clash_thres:\n",
    "                count_ident += 1\n",
    "        else:\n",
    "            if clash_perc > clash_thres:\n",
    "                count_ident += 1\n",
    "                \n",
    "    nbr_cpgs = len(cpg_positions)\n",
    "    perc_exp_clash_ident = float(count_ident)/float(nbr_cpgs)\n",
    "    \n",
    "    return perc_exp_clash_ident\n",
    "\n",
    "def calc_score_lists(df_sliding_windows, x_y_clash_dict_norm, params):\n",
    "    column_names = [\"refid_NOR\", \"trans_id\", \"refid\", \"NOR_nbr\", \"window_nbr\", \"nbr_CpGs\", \"nuc_rel_center\", \"nuc_region_length\"] + params\n",
    "    info_dict = dict()\n",
    "    for col in column_names:\n",
    "        info_dict[col] = []\n",
    "        \n",
    "    all_refids = list(df_sliding_windows[\"refid\"])\n",
    "    all_NOR_nbrs = list(df_sliding_windows[\"NOR_nbr\"])\n",
    "    refid_NORs = []\n",
    "    for ref, nor in zip(all_refids, all_NOR_nbrs):\n",
    "        refid_NORs.append(str(ref)+\"-\"+str(nor))\n",
    "    \n",
    "    info_dict[\"refid_NOR\"].extend(refid_NORs)\n",
    "    info_dict[\"trans_id\"].extend(list(df_sliding_windows[\"trans_id\"]))\n",
    "    info_dict[\"refid\"].extend(all_refids)\n",
    "    info_dict[\"NOR_nbr\"].extend(all_NOR_nbrs)\n",
    "    info_dict[\"window_nbr\"].extend( list(df_sliding_windows[\"window_nbr\"]))\n",
    "    info_dict[\"nbr_CpGs\"].extend(list(df_sliding_windows[\"nbr_meth_CpGs\"])  )\n",
    "    info_dict[\"nuc_region_length\"].extend(list(df_sliding_windows[\"nuc_region_length\"]))\n",
    "    info_dict[\"nuc_rel_center\"].extend(list(df_sliding_windows[\"nuc_rel_center\"]))\n",
    "\n",
    "    all_scores =  list(df_sliding_windows[\"meth_rates_window\"]) #{34: 0.0, 35: 0.0,...}\n",
    "    c = 0\n",
    "    for row_df in tqdm(range(len(all_scores))):\n",
    "        c += 1\n",
    "        \n",
    "        # meth_rates_window = ast.literal_eval(all_scores[row_df])\n",
    "        meth_rates_window = all_scores[row_df]\n",
    "    \n",
    "        for param_str in params:\n",
    "            clash_thres = float(re.findall(r'\\d+', param_str)[0]) #c5m0\n",
    "            meth_thres = float(re.findall(r'\\d+', param_str)[1])\n",
    "            \n",
    "            perc_clash_ident = calc_perc_exp_clash_ident(x_y_clash_dict_norm, meth_rates_window, meth_thres, clash_thres)\n",
    "            info_dict[param_str].append(perc_clash_ident)\n",
    "            \n",
    "    #Built dataframe \n",
    "    df_scores = pd.DataFrame(0, index = np.arange(len(info_dict[column_names[0]])),columns = column_names)\n",
    "    for feat in column_names:\n",
    "        df_scores[feat] = info_dict[feat]\n",
    "\n",
    "    return df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NDR_score_exp = calc_score_lists(df_NDR_sliding_windows, x_y_clash_dict_norm, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NDR_score_random = calc_score_lists(df_NDR_sliding_windows_random, x_y_clash_dict_norm, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NDR_score_exp.shape, df_NDR_score_random.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NDR_score_exp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NOR_score_exp = calc_score_lists(df_NOR_sliding_windows, x_y_clash_dict_norm, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NOR_score_random = calc_score_lists(df_NOR_sliding_windows_random, x_y_clash_dict_norm, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NOR_score_exp.shape, df_NOR_score_random.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NOR_score_exp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cohens_d(list_EXP,list_RAND):\n",
    "    mEXP = np.mean(list_EXP)\n",
    "    sdEXP = np.std(list_EXP)\n",
    "    \n",
    "    mRAND = np.mean(list_RAND)\n",
    "    sdRAND = np.std(list_RAND)\n",
    "    \n",
    "    denom = np.sqrt(float(sdEXP**2 + sdRAND**2)/2.0)\n",
    "    cohens_d = float(mEXP-mRAND)/float(denom + 1e-6)\n",
    "    \n",
    "    return cohens_d\n",
    "\n",
    "def make_df_p_vals_cohens_d(df_scores_EXP, df_scores_RAND, params):\n",
    "    column_names = [\"nbr_CpGs\", \"parameter\", \"N_EXP\", \"N_RAND\", \"mean_EXP\", \"median_EXP\", \"std_EXP\", \"mean_RAND\",\n",
    "                    \"median_RAND\", \"std_RAND\", \"cohens_d\", \"is_normal_EXP\", \"is_normal_RAND\", \"pval_ttest\",\n",
    "                    \"t_stat\", \"pval_ranksums\", \"pval_ks_2samp\"]\n",
    "    info_dict = dict()\n",
    "    for col in column_names:\n",
    "        info_dict[col] = []\n",
    "\n",
    "    nbr_CpGs_list = list(set(list(df_scores_EXP[\"nbr_CpGs\"])))\n",
    "\n",
    "    for nbr_CpGs in nbr_CpGs_list:\n",
    "        df_scores_EXP_tmp = df_scores_EXP.loc[df_scores_EXP[\"nbr_CpGs\"] == nbr_CpGs]\n",
    "        df_scores_RAND_tmp = df_scores_RAND.loc[df_scores_RAND[\"nbr_CpGs\"] == nbr_CpGs]\n",
    "                    \n",
    "        for p in range(len(params)):\n",
    "            par_name = params[p]\n",
    "            EXP_scores = list(df_scores_EXP_tmp[par_name])\n",
    "            RAND_scores = list(df_scores_RAND_tmp[par_name])\n",
    "            \n",
    "            info_dict[\"nbr_CpGs\"].append(nbr_CpGs)\n",
    "            info_dict[\"parameter\"].append(par_name)\n",
    "            \n",
    "            info_dict[\"N_EXP\"].append(len(EXP_scores))\n",
    "            info_dict[\"N_RAND\"].append(len(RAND_scores))\n",
    "            \n",
    "            info_dict[\"mean_EXP\"].append(np.mean(EXP_scores))\n",
    "            info_dict[\"median_EXP\"].append(np.median(EXP_scores))\n",
    "            info_dict[\"std_EXP\"].append(np.std(EXP_scores))\n",
    "            \n",
    "            info_dict[\"mean_RAND\"].append(np.mean(RAND_scores))\n",
    "            info_dict[\"median_RAND\"].append(np.median(RAND_scores))\n",
    "            info_dict[\"std_RAND\"].append(np.std(RAND_scores))\n",
    "            \n",
    "            #EFFECT SIZE\n",
    "            cohens_d = calculate_cohens_d(EXP_scores, RAND_scores)\n",
    "            info_dict[\"cohens_d\"].append(cohens_d)\n",
    "            \n",
    "            #STAT TESTS\n",
    "            #is normal distributed? This function tests the null hypothesis that a sample comes from a normal distribution. If small -> ost likely not normal dustributed\n",
    "            pval_normal_EXP = stats.normaltest(EXP_scores)[1] if len(EXP_scores) >= 8 else -1\n",
    "            pval_normal_RAND = stats.normaltest(RAND_scores)[1] if len(EXP_scores) >= 8 else -1\n",
    "            \n",
    "            #students t\n",
    "            ttest_res = stats.ttest_ind(EXP_scores,RAND_scores,equal_var = False)\n",
    "            t_stat = ttest_res[0]\n",
    "            p_val_ttest = float(ttest_res[1])/2.0\n",
    "            \n",
    "            #ranksums, kstest\n",
    "            ranksums = scipy.stats.ranksums(EXP_scores,RAND_scores)[1]\n",
    "            ks_2samp = scipy.stats.ks_2samp(EXP_scores,RAND_scores)[1]\n",
    "    \n",
    "            info_dict[\"is_normal_EXP\"].append(pval_normal_EXP)\n",
    "            info_dict[\"is_normal_RAND\"].append(pval_normal_RAND)\n",
    "            info_dict[\"pval_ttest\"].append(p_val_ttest)\n",
    "            info_dict[\"t_stat\"].append(t_stat)\n",
    "            info_dict[\"pval_ranksums\"].append(ranksums)\n",
    "            info_dict[\"pval_ks_2samp\"].append(ks_2samp)\n",
    "            \n",
    "    #Built dataframe\n",
    "    df = pd.DataFrame(0, index = np.arange(len(info_dict[\"nbr_CpGs\"])),columns = column_names)\n",
    "    for feat in column_names:\n",
    "        df[feat] = info_dict[feat]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NDR_pvalues = make_df_p_vals_cohens_d(df_NDR_score_exp, df_NDR_score_random, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NDR_pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = df_NDR_pvalues.groupby(by='parameter')\n",
    "for par, df_tmp in groups:\n",
    "    plt.scatter(df_tmp['nbr_CpGs'], df_tmp['N_EXP'], label=par)\n",
    "plt.legend()\n",
    "plt.xlabel('nCPGs')\n",
    "plt.ylabel('Size of sample Cohen D')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NOR_pvalues = make_df_p_vals_cohens_d(df_NOR_score_exp, df_NOR_score_random, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NOR_pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = df_NOR_pvalues.groupby(by='parameter')\n",
    "for par, df_tmp in groups:\n",
    "    plt.scatter(df_tmp['nbr_CpGs'], df_tmp['N_EXP'], label=par)\n",
    "plt.legend()\n",
    "plt.xlabel('nCPGs')\n",
    "plt.ylabel('Size of sample Cohen D')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_nbr_CpGs_cohensd(df_values, params):\n",
    "    plt.figure(figsize=(15,7))\n",
    "    ax = plt.subplot(1,1,1)\n",
    "    \n",
    "    nbr_CpGs_list = sorted(list(set(list(df_values[\"nbr_CpGs\"]))))\n",
    "\n",
    "    for par_name in params:\n",
    "        \n",
    "        df_values_tmp = df_values.loc[df_values[\"parameter\"] == par_name]\n",
    "        \n",
    "        x_nbr_cpg_vals = list(df_values_tmp[\"nbr_CpGs\"])\n",
    "        y_cohens_d_vals = list(df_values_tmp[\"cohens_d\"])\n",
    "        \n",
    "        if \"m0\" in par_name:\n",
    "            c = \"#117A65\"\n",
    "        if \"m10\" in par_name:\n",
    "            c = \"#45B39D\"\n",
    "        if \"m20\" in par_name:\n",
    "            c = \"#EB984E\"\n",
    "        if \"c5\" in par_name:\n",
    "            m = \"*\"\n",
    "            ms = 15\n",
    "        if \"c10\" in par_name:\n",
    "            m = \"^\"\n",
    "            ms = 10\n",
    "        if \"c20\" in par_name:\n",
    "            m = \"s\"\n",
    "            ms = 10\n",
    "        if \"c50\" in par_name:\n",
    "            m = \"o\"\n",
    "            ms = 10\n",
    "        \n",
    "        \n",
    "        plt.plot(x_nbr_cpg_vals, y_cohens_d_vals, linestyle=\"-\", color=c, marker=m, markersize=ms, label=par_name)\n",
    "    \n",
    "    \n",
    "    plt.axhline(y=0.2, linewidth=1, color = '#2C3E50',linestyle='--')\n",
    "    plt.axhline(y=0.5, linewidth=1, color = '#2C3E50',linestyle='--')\n",
    "    plt.axhline(y=0.8, linewidth=1, color = '#2C3E50',linestyle='--')\n",
    "    \n",
    "    e = 0.02\n",
    "    ax.text(-1.8,0.2+e,\"Small ES\")\n",
    "    ax.text(-1.8,0.5+e,\"Medium ES\")\n",
    "    ax.text(-1.8,0.8+e,\"Large ES\")\n",
    "\n",
    "    ax.set_ylabel(\"Cohen's d\")\n",
    "    ax.set_xlabel(\"Number of CpGs in sliding window\")   \n",
    "\n",
    "    plt.xlim(-2,35)\n",
    "    plt.ylim(-3,3)\n",
    "\n",
    "    legend = ax.legend(loc=\"lower left\",ncol=4,frameon = 1,prop={'size':14})\n",
    "    legend.get_frame().set_facecolor('white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_nbr_CpGs_cohensd(df_NDR_pvalues, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_nbr_CpGs_cohensd(df_NOR_pvalues, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 'c10m20'\n",
    "plt.hist(df_NDR_pvalues[np.logical_and(df_NDR_pvalues['nbr_CpGs'].between(10,20), df_NDR_pvalues['parameter'] == p)]['cohens_d'], label='LNDR', alpha=0.7)\n",
    "plt.hist(df_NOR_pvalues[np.logical_and(df_NOR_pvalues['nbr_CpGs'].between(10,20), df_NOR_pvalues['parameter'] == p)]['cohens_d'], label='HNDR', alpha=0.7)\n",
    "plt.legend()\n",
    "plt.xlim(0)\n",
    "plt.title(f'{p} nCpG\\'s between 10 and 20')\n",
    "plt.xlabel('cohen\\'s d')\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 'c5m0'\n",
    "plt.hist(df_NDR_pvalues[np.logical_and(df_NDR_pvalues['nbr_CpGs'] >= 10, df_NDR_pvalues['parameter'] == p)]['cohens_d'], label='LNDR', alpha=0.7)\n",
    "plt.hist(df_NOR_pvalues[np.logical_and(df_NOR_pvalues['nbr_CpGs'] >= 10, df_NOR_pvalues['parameter'] == p)]['cohens_d'], label='HNDR', alpha=0.7)\n",
    "plt.legend()\n",
    "plt.xlim(0)\n",
    "plt.title(f'{p} nCpG\\'s >= 10')\n",
    "plt.xlabel('cohen\\'s d')\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NOR_pvalues[np.logical_and(df_NOR_pvalues['nbr_CpGs'] >= 10, df_NOR_pvalues['parameter'] == 'c5m0')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "helms-lab-jupyter",
   "language": "python",
   "name": "helms-lab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
